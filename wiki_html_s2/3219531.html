<!DOCTYPE html>

<html class="client-nojs" dir="ltr" lang="ja">
<head>
<meta charset="utf-8"/>
<title>ディープラーニング - Wikipedia</title><style type="text/css">h1.firstHeading{line-height:1.2} .infobox {     border: 1px solid #aaa; background: #f9f9f9; color: black; margin-bottom: 0.5em; margin-left: 1em; padding: .2em; float: right; clear: right; } .infobox tr { vertical-align: top; } .infobox caption { margin-left: inherit; } .infobox.bordered { border-collapse: collapse; } .infobox.bordered td, .infobox.bordered th { border: 1px solid #aaa; } .infobox.sisterproject { width: 20em; font-size: 70%; } div[role="navigation"]{display:none;} #content{ font-size: 80%; } </style>
<script>function init(){for(var a,e,b=[],f=location.search.split("?")[1].split("&"),h=f.length,c=0;c<h;c++)a=f[c].split("="),e=decodeURIComponent(a[0]),b[e]=decodeURIComponent(a[1]);a=[];if("false"===b.infobox){b=document.querySelectorAll("[class^='infobox']");0<b.length&&(a=a.concat(b));b=document.querySelectorAll("[id^='infobox']");0<b.length&&(a=a.concat(b));b=document.querySelectorAll("table");0<b.length&&(a=a.concat(b));for(var d in a)for(var g in a[d])console.log(a[d][g]),a[d][g].style.display="none"}};</script></head>
<body onLoad="init()" class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-ディープラーニング rootpage-ディープラーニング skin-vector action-view skin-vector-legacy"><div class="noprint" id="mw-page-base"></div>
<div class="noprint" id="mw-head-base"></div>
<div class="mw-body" id="content" role="main">
<a id="top"></a>
<div id="siteNotice"></div>
<div class="mw-indicators">
</div>
<h1 class="firstHeading" id="firstHeading">ディープラーニング</h1>
<div class="vector-body" id="bodyContent">

<div id="contentSub"></div>
<div id="contentSub2"></div>
<div id="jump-to-nav"></div>
<a class="mw-jump-link" href="#mw-head">ナビゲーションに移動</a>
<a class="mw-jump-link" href="#searchInput">検索に移動</a>
<div class="mw-body-content mw-content-ltr" dir="ltr" id="mw-content-text" lang="ja"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:250px;margin:0 0 1.0em 1.0em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em">機械学習および<br/><a href="." id="link_i_1" title="データマイニング">データマイニング</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="/wiki/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:Kernel_Machine.svg" title="ファイル:Kernel Machine.svg">ファイル:Kernel Machine.svg</a></td></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">問題</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_2" title="分類 (統計学)">分類</a></li>
<li><a href="." id="link_i_3" title="データ・クラスタリング">クラスタリング</a></li>
<li><a href="." id="link_i_4" title="回帰分析">回帰</a></li>
<li><a href="." id="link_i_5" title="異常検知">異常検知</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_6" title="相関ルール学習 (存在しないページ)">相関ルール</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Association_rule_learning&amp;action=edit&amp;redlink=1" title="En:Association rule learning (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_7" title="強化学習">強化学習</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_8" title="構造化予測 (存在しないページ)">構造化予測</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Structured_prediction&amp;action=edit&amp;redlink=1" title="En:Structured prediction (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_9" title="特徴量設計 (存在しないページ)">特徴量設計</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Feature_engineering&amp;action=edit&amp;redlink=1" title="En:Feature engineering (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_10" title="表現学習 (存在しないページ)">表現学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Feature_learning&amp;action=edit&amp;redlink=1" title="En:Feature learning (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_11" title="オンライン機械学習 (存在しないページ)">オンライン学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Online_machine_learning&amp;action=edit&amp;redlink=1" title="En:Online machine learning (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_12" title="半教師あり学習 (存在しないページ)">半教師あり学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Semi-supervised_learning&amp;action=edit&amp;redlink=1" title="En:Semi-supervised learning (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_13" title="教師なし学習">教師なし学習</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_14" title="ランキング学習 (存在しないページ)">ランキング学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Learning_to_rank&amp;action=edit&amp;redlink=1" title="En:Learning to rank (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_15" title="文法獲得 (存在しないページ)">文法獲得 </a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Grammar_induction&amp;action=edit&amp;redlink=1" title="En:Grammar induction (存在しないページ)">英語版</a>）</span></span></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="." id="link_i_16" title="教師あり学習">教師あり学習</a><span style="font-weight:normal !important;"><small>（<b><a href="." id="link_i_2" title="分類 (統計学)">分類</a></b> • <b> <a href="." id="link_i_4" title="回帰分析">回帰</a></b>）</small></span></div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_17" title="決定木学習 (存在しないページ)">決定木</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Decision_tree_learning&amp;action=edit&amp;redlink=1" title="En:Decision tree learning (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_18" title="アンサンブル学習 (存在しないページ)">アンサンブル</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Ensemble_learning&amp;action=edit&amp;redlink=1" title="En:Ensemble learning (存在しないページ)">英語版</a>）</span></span><br/>（<a href="." id="link_i_19" title="バギング">バギング</a>、<a href="." id="link_i_20" title="ブースティング">ブースティング</a>、<br/><a href="." id="link_i_21" title="ランダムフォレスト">ランダムフォレスト</a>）</li>
<li><a href="." id="link_i_22" title="K近傍法">k-NN</a></li>
<li><a href="." id="link_i_23" title="線形回帰">線形回帰</a></li>
<li><a href="." id="link_i_24" title="単純ベイズ分類器">単純ベイズ</a></li>
<li><a href="." id="link_i_25" title="ニューラルネットワーク">ニューラルネットワーク</a></li>
<li><a href="." id="link_i_26" title="ロジスティック回帰">ロジスティック回帰</a></li>
<li><a href="." id="link_i_27" title="パーセプトロン">パーセプトロン</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_28" title="関連ベクトルマシン (存在しないページ)">関連ベクトルマシン (RVM)</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Relevance_vector_machine&amp;action=edit&amp;redlink=1" title="En:Relevance vector machine (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_29" title="サポートベクターマシン">サポートベクトルマシン (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="." id="link_i_3" title="データ・クラスタリング">クラスタリング</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_30" title="BIRCH (存在しないページ)">BIRCH</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:BIRCH&amp;action=edit&amp;redlink=1" title="En:BIRCH (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_31" title="階層的クラスタリング (存在しないページ)">階層的</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Hierarchical_clustering&amp;action=edit&amp;redlink=1" title="En:Hierarchical clustering (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_32" title="K平均法">k平均法</a></li>
<li><a href="." id="link_i_33" title="EMアルゴリズム">期待値最大化法 (EM)</a></li>
<li><br/><a href="." id="link_i_34" title="DBSCAN">DBSCAN</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_35" title="OPTICSアルゴリズム (存在しないページ)">OPTICS</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:OPTICS&amp;action=edit&amp;redlink=1" title="En:OPTICS (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_36" title="平均値シフト (存在しないページ)">平均値シフト</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Mean-shift&amp;action=edit&amp;redlink=1" title="En:Mean-shift (存在しないページ)">英語版</a>）</span></span></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_37" title="次元削減 (存在しないページ)">次元削減</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Dimensionality_reduction&amp;action=edit&amp;redlink=1" title="En:Dimensionality reduction (存在しないページ)">英語版</a>）</span></span></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_38" title="因子分析">因子分析</a></li>
<li><a href="." id="link_i_39" title="カノニカル相関">CCA</a></li>
<li><a href="." id="link_i_40" title="独立成分分析">ICA</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_41" title="線形判別分析 (存在しないページ)">LDA</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Linear_discriminant_analysis&amp;action=edit&amp;redlink=1" title="En:Linear discriminant analysis (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_42" title="非負値行列因子分解 (存在しないページ)">NMF</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Non-negative_matrix_factorization&amp;action=edit&amp;redlink=1" title="En:Non-negative matrix factorization (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_43" title="主成分分析">PCA</a></li>
<li><a href="." id="link_i_44" title="T分布型確率的近傍埋め込み法">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_8" title="構造化予測 (存在しないページ)">構造化予測</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Structured_prediction&amp;action=edit&amp;redlink=1" title="En:Structured prediction (存在しないページ)">英語版</a>）</span></span></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_45" title="グラフィカルモデル">グラフィカルモデル</a><br/>（<a href="." id="link_i_46" title="ベイジアンネットワーク">ベイジアンネットワーク</a>、<br/><a href="." id="link_i_47" title="条件付き確率場">CRF</a>、<a href="." id="link_i_48" title="隠れマルコフモデル">HMM</a>）</li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="." id="link_i_5" title="異常検知">異常検知</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_22" title="K近傍法">k-NN</a></li>
<li><a href="." id="link_i_49" title="局所外れ値因子法">局所外れ値因子法</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="." id="link_i_25" title="ニューラルネットワーク">ニューラルネットワーク</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_50" title="オートエンコーダ">オートエンコーダ</a></li>
<li><a class="mw-selflink selflink">ディープラーニング</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_51" title="DeepDream (存在しないページ)">DeepDream</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:DeepDream&amp;action=edit&amp;redlink=1" title="En:DeepDream (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_52" title="多層パーセプトロン">多層パーセプトロン</a></li>
<li><a href="." id="link_i_53" title="回帰型ニューラルネットワーク">RNN</a>
<ul><li><a href="." id="link_i_54" title="長・短期記憶">LSTM</a></li>
<li><a href="." id="link_i_55" title="ゲート付き回帰型ユニット">GRU</a></li></ul></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_56" title="制約ボルツマンマシン (存在しないページ)">制約ボルツマンマシン</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Restricted_Boltzmann_machine&amp;action=edit&amp;redlink=1" title="En:Restricted Boltzmann machine (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_57" title="自己組織化写像">SOM</a></li>
<li><a href="." id="link_i_58" title="畳み込みニューラルネットワーク">畳み込みニューラルネットワーク</a>
<ul><li><a href="." id="link_i_59" title="U-Net (存在しないページ)">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="." id="link_i_7" title="強化学習">強化学習</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_60" title="Q学習">Q学習</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_61" title="SARSAアルゴリズム (存在しないページ)">SARSA</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:State-Action-Reward-State-Action&amp;action=edit&amp;redlink=1" title="En:State-Action-Reward-State-Action (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_62" title="時間差分学習 (存在しないページ)">時間差分 (TD)</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Temporal_Difference_Learning&amp;action=edit&amp;redlink=1" title="En:Temporal Difference Learning (存在しないページ)">英語版</a>）</span></span></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">理論</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_63" title="偏りと分散">偏りと分散</a>のトレードオフ</li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_64" title="計算論的学習理論 (存在しないページ)">計算論的学習理論</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Computational_learning_theory&amp;action=edit&amp;redlink=1" title="En:Computational learning theory (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_65" title="経験損失最小化 (存在しないページ)">経験損失最小化</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Empirical_risk_minimization&amp;action=edit&amp;redlink=1" title="En:Empirical risk minimization (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_66" title="オッカム学習 (存在しないページ)">オッカム学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Occam_learning&amp;action=edit&amp;redlink=1" title="En:Occam learning (存在しないページ)">英語版</a>）</span></span></li>
<li><a href="." id="link_i_67" title="確率的で近似的に正しい学習">PAC学習</a></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_68" title="統計的学習理論 (存在しないページ)">統計的学習</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Statistical_learning_theory&amp;action=edit&amp;redlink=1" title="En:Statistical learning theory (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_69" title="ヴァプニーク・チェルヴォーネンキス理論 (存在しないページ)">VC理論</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Vapnik%E2%80%93Chervonenkis_theory&amp;action=edit&amp;redlink=1" title="En:Vapnik–Chervonenkis theory (存在しないページ)">英語版</a>）</span></span></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">学会・論文誌等</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_70" title="NIPS (存在しないページ)">NIPS</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Conference_on_Neural_Information_Processing_Systems&amp;action=edit&amp;redlink=1" title="En:Conference on Neural Information Processing Systems (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_71" title="ICML (存在しないページ)">ICML</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:International_Conference_on_Machine_Learning&amp;action=edit&amp;redlink=1" title="En:International Conference on Machine Learning (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_72" title="Machine learning (書籍) (存在しないページ)">ML</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Machine_Learning_(journal)&amp;action=edit&amp;redlink=1" title="En:Machine Learning (journal) (存在しないページ)">英語版</a>）</span></span></li>
<li><span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a href="." id="link_i_73" title="JMLR (存在しないページ)">JMLR</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Journal_of_Machine_Learning_Research&amp;action=edit&amp;redlink=1" title="En:Journal of Machine Learning Research (存在しないページ)">英語版</a>）</span></span></li>
<li><a class="external text" href="http://arxiv.org/list/cs.LG/recent" rel="nofollow">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">全般</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="." id="link_i_74" title="統計学および機械学習の評価指標">統計学および機械学習の評価指標</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:75%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88:Machine_learning_bar" title="テンプレート:Machine learning bar"><abbr title="このテンプレートを表示します">表</abbr></a></li><li class="nv-talk"><a class="new" href="/w/index.php?title=%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88%E3%83%BB%E3%83%88%E3%83%BC%E3%82%AF:Machine_learning_bar&amp;action=edit&amp;redlink=1" title="テンプレート・トーク:Machine learning bar (存在しないページ)"><span title="このテンプレートのノートを表示します">話</span></a></li><li class="nv-edit"><a class="external text" href="http://localhost:8080/w/index.php?title=%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88:Machine_learning_bar&amp;action=edit" rel="nofollow"><span title="このテンプレートを編集します">編</span></a></li><li class="nv-history"><a class="external text" href="http://localhost:8080/w/index.php?title=%E3%83%86%E3%83%B3%E3%83%97%E3%83%AC%E3%83%BC%E3%83%88:Machine_learning_bar&amp;action=history" rel="nofollow"><span title="このテンプレートの過去の版を表示します">歴</span></a></li></ul></div></td></tr></tbody></table>
<p><b>ディープラーニング</b>（<a href="." id="link_a_75" title="英語">英</a>: <span lang="en">Deep learning</span>）または<b>深層学習</b>（しんそうがくしゅう）とは、対象の全体像から細部までの各々の粒度の概念を階層構造として関連させて学習する手法のことである<sup class="reference" id="cite_ref-:1_1-0"><a href="#cite_note-:1-1">[1]</a></sup><sup class="reference" id="cite_ref-:0_2-0"><a href="#cite_note-:0-2">[注釈 1]</a></sup>。深層学習として最も普及した手法は、（狭義には4層以上<sup class="reference" id="cite_ref-asou_3-0"><a href="#cite_note-asou-3">[2]</a></sup><sup class="reference" id="cite_ref-4"><a href="#cite_note-4">[注釈 2]</a></sup>の）多層の人工<a href="." id="link_a_25" title="ニューラルネットワーク">ニューラルネットワーク</a>（ディープニューラルネットワーク、<a href="." id="link_a_75" title="英語">英</a>: <span lang="en">deep neural network</span>; DNN）による<a href="." id="link_a_76" title="機械学習">機械学習</a>手法である<sup class="reference" id="cite_ref-5"><a href="#cite_note-5">[3]</a></sup>。多層<a href="." id="link_a_25" title="ニューラルネットワーク">ニューラルネットワーク</a>については、<a href="." id="link_a_77" title="ジェフリー・ヒントン">ジェフリー・ヒントン</a>の研究チームが<a href="." id="link_a_78" title="2006年">2006年</a>に考案したスタックド<a href="." id="link_a_50" title="オートエンコーダ">オートエンコーダ</a>が直接の起源となった。
</p><p>要素技術としては<a href="." id="link_a_79" title="バックプロパゲーション">バックプロパゲーション</a>など、20世紀のうちに開発されていたものの、4層以上の深層ニューラルネットについて、局所最適解や勾配消失などの技術的な問題によって十分学習させられず、性能も芳しくなかった。しかし、21世紀に入って、スタックド<a href="." id="link_a_50" title="オートエンコーダ">オートエンコーダ</a>を始めとする<a href="." id="link_a_77" title="ジェフリー・ヒントン">ジェフリー・ヒントン</a>らによる多層ニューラルネットワークの学習の研究や、学習に必要な計算機の能力向上、および、インターネットの発展による学習データの流通により、十分に学習させられるようになった。その結果、<a href="." id="link_a_80" title="音声認識">音声</a>・<a href="." id="link_a_81" title="画像認識">画像</a>・<a href="." id="link_a_82" title="自然言語処理">自然言語</a>を対象とする諸問題に対し、他の手法を圧倒する高い性能を示し<sup class="reference" id="cite_ref-Okatani_DL_6-0"><a href="#cite_note-Okatani_DL-6">[4]</a></sup>、2010年代に普及した<sup class="reference" id="cite_ref-asou_3-1"><a href="#cite_note-asou-3">[2]</a></sup>。学界では更に<a href="." id="link_a_83" title="抽象化">抽象化</a>された数学的概念によるディープラーニングが研究されている<sup class="reference" id="cite_ref-:0_7-0"><a href="#cite_note-:0-7">[5]</a></sup><sup class="reference" id="cite_ref-:1_8-0"><a href="#cite_note-:1-8">[注釈 3]</a></sup>。
</p>
<div aria-labelledby="mw-toc-heading" class="toc" id="toc" role="navigation"><input class="toctogglecheckbox" id="toctogglecheckbox" role="button" style="display:none" type="checkbox"/><div class="toctitle" dir="ltr" lang="ja"><h2 id="mw-toc-heading">目次</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#概要"><span class="tocnumber">1</span> <span class="toctext">概要</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#歴史"><span class="tocnumber">2</span> <span class="toctext">歴史</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#前史"><span class="tocnumber">2.1</span> <span class="toctext">前史</span></a>
<ul>
<li class="toclevel-3 tocsection-4"><a href="#ネオコグニトロン（1979年）"><span class="tocnumber">2.1.1</span> <span class="toctext">ネオコグニトロン（1979年）</span></a></li>
<li class="toclevel-3 tocsection-5"><a href="#LeNet-5（1998年）"><span class="tocnumber">2.1.2</span> <span class="toctext">LeNet-5（1998年）</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-6"><a href="#多層ニューラルネットワークの実現（2006_-_2012年）"><span class="tocnumber">2.2</span> <span class="toctext">多層ニューラルネットワークの実現（2006 - 2012年）</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#学習モデルの複雑化・数学的抽象化の時代（2012年_-_現在）"><span class="tocnumber">2.3</span> <span class="toctext">学習モデルの複雑化・数学的抽象化の時代（2012年 - 現在）</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#利用"><span class="tocnumber">3</span> <span class="toctext">利用</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#ネットワークモデル"><span class="tocnumber">4</span> <span class="toctext">ネットワークモデル</span></a>
<ul>
<li class="toclevel-2 tocsection-10"><a href="#畳み込みニューラルネットワーク"><span class="tocnumber">4.1</span> <span class="toctext">畳み込みニューラルネットワーク</span></a></li>
<li class="toclevel-2 tocsection-11"><a href="#スタックトオートエンコーダ"><span class="tocnumber">4.2</span> <span class="toctext">スタックトオートエンコーダ</span></a></li>
<li class="toclevel-2 tocsection-12"><a href="#Residual_network"><span class="tocnumber">4.3</span> <span class="toctext">Residual network</span></a></li>
<li class="toclevel-2 tocsection-13"><a href="#敵対的生成ネットワーク"><span class="tocnumber">4.4</span> <span class="toctext">敵対的生成ネットワーク</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#ボルツマンマシン"><span class="tocnumber">4.5</span> <span class="toctext">ボルツマンマシン</span></a>
<ul>
<li class="toclevel-3 tocsection-15"><a href="#制限ボルツマンマシン"><span class="tocnumber">4.5.1</span> <span class="toctext">制限ボルツマンマシン</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-16"><a href="#回帰型ニューラルネットワーク"><span class="tocnumber">4.6</span> <span class="toctext">回帰型ニューラルネットワーク</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-17"><a href="#特有の問題"><span class="tocnumber">5</span> <span class="toctext">特有の問題</span></a>
<ul>
<li class="toclevel-2 tocsection-18"><a href="#勾配消失問題"><span class="tocnumber">5.1</span> <span class="toctext">勾配消失問題</span></a></li>
<li class="toclevel-2 tocsection-19"><a href="#過学習"><span class="tocnumber">5.2</span> <span class="toctext">過学習</span></a></li>
<li class="toclevel-2 tocsection-20"><a href="#局所最適解へのトラップ"><span class="tocnumber">5.3</span> <span class="toctext">局所最適解へのトラップ</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-21"><a href="#テクニック"><span class="tocnumber">6</span> <span class="toctext">テクニック</span></a>
<ul>
<li class="toclevel-2 tocsection-22"><a href="#データ拡張"><span class="tocnumber">6.1</span> <span class="toctext">データ拡張</span></a></li>
<li class="toclevel-2 tocsection-23"><a href="#活性化関数"><span class="tocnumber">6.2</span> <span class="toctext">活性化関数</span></a>
<ul>
<li class="toclevel-3 tocsection-24"><a href="#ReLU"><span class="tocnumber">6.2.1</span> <span class="toctext">ReLU</span></a></li>
<li class="toclevel-3 tocsection-25"><a href="#maxout"><span class="tocnumber">6.2.2</span> <span class="toctext">maxout</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-26"><a href="#ドロップアウト"><span class="tocnumber">6.3</span> <span class="toctext">ドロップアウト</span></a></li>
<li class="toclevel-2 tocsection-27"><a href="#スパースコーディング"><span class="tocnumber">6.4</span> <span class="toctext">スパースコーディング</span></a></li>
<li class="toclevel-2 tocsection-28"><a href="#バッチ正則化"><span class="tocnumber">6.5</span> <span class="toctext">バッチ正則化</span></a></li>
<li class="toclevel-2 tocsection-29"><a href="#ミニバッチ法"><span class="tocnumber">6.6</span> <span class="toctext">ミニバッチ法</span></a></li>
<li class="toclevel-2 tocsection-30"><a href="#蒸留"><span class="tocnumber">6.7</span> <span class="toctext">蒸留</span></a></li>
<li class="toclevel-2 tocsection-31"><a href="#事前学習_(Pre-training)"><span class="tocnumber">6.8</span> <span class="toctext">事前学習 (Pre-training)</span></a></li>
<li class="toclevel-2 tocsection-32"><a href="#AdaGrad"><span class="tocnumber">6.9</span> <span class="toctext">AdaGrad</span></a></li>
<li class="toclevel-2 tocsection-33"><a href="#Adam"><span class="tocnumber">6.10</span> <span class="toctext">Adam</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-34"><a href="#ライブラリ"><span class="tocnumber">7</span> <span class="toctext">ライブラリ</span></a></li>
<li class="toclevel-1 tocsection-35"><a href="#脚注"><span class="tocnumber">8</span> <span class="toctext">脚注</span></a>
<ul>
<li class="toclevel-2 tocsection-36"><a href="#注釈"><span class="tocnumber">8.1</span> <span class="toctext">注釈</span></a></li>
<li class="toclevel-2 tocsection-37"><a href="#出典"><span class="tocnumber">8.2</span> <span class="toctext">出典</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-38"><a href="#参考文献"><span class="tocnumber">9</span> <span class="toctext">参考文献</span></a></li>
<li class="toclevel-1 tocsection-39"><a href="#関連項目"><span class="tocnumber">10</span> <span class="toctext">関連項目</span></a></li>
</ul>
</div>
<h2><span id=".E6.A6.82.E8.A6.81"></span><span class="mw-headline" id="概要">概要</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=1" title="節を編集: 概要">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>ディープラーニングは、学習に用いる具体的な数学的概念はどうであれ、対象の全体像から細部までの各々の粒度の概念を階層構造として関連させて学習する手法を指す<sup class="reference" id="cite_ref-:1_1-1"><a href="#cite_note-:1-1">[1]</a></sup><sup class="reference" id="cite_ref-:0_2-1"><a href="#cite_note-:0-2">[注釈 1]</a></sup>。<a href="/wiki/21%E4%B8%96%E7%B4%80" title="21世紀">21世紀</a>に入って、<a href="/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%80" title="オートエンコーダ">オートエンコーダ</a>を始めとする<a href="/wiki/%E3%82%B8%E3%82%A7%E3%83%95%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%92%E3%83%B3%E3%83%88%E3%83%B3" title="ジェフリー・ヒントン">ジェフリー・ヒントン</a>らによる多層<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>による学習の研究や、学習に必要な計算機の能力向上、および、インターネットの発展による学習データの流通により、多層ニューラルネットによる手法が最初に確立された。その結果、<a href="/wiki/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98" title="音声認識">音声</a>・<a class="mw-redirect" href="/wiki/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98" title="画像認識">画像</a>・<a href="/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86" title="自然言語処理">自然言語</a>を対象とする諸問題に対し、他の手法を圧倒する高い性能を示し<sup class="reference" id="cite_ref-Okatani_DL_6-1"><a href="#cite_note-Okatani_DL-6">[4]</a></sup>、2010年代に普及した<sup class="reference" id="cite_ref-asou_3-2"><a href="#cite_note-asou-3">[2]</a></sup>。結果として（狭義には4層以上<sup class="reference" id="cite_ref-asou_3-3"><a href="#cite_note-asou-3">[2]</a></sup><sup class="reference" id="cite_ref-9"><a href="#cite_note-9">[注釈 4]</a></sup>の）多層の人工<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>（ディープニューラルネットワーク、<a href="/wiki/%E8%8B%B1%E8%AA%9E" title="英語">英</a>: <span lang="en">deep neural network</span>; DNN）による<a href="/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92" title="機械学習">機械学習</a>手法<sup class="reference" id="cite_ref-10"><a href="#cite_note-10">[6]</a></sup>が広く知られるようになったが、<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>以外でも深層学習は構成可能であり、現在は<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>よりも抽象的な深層学習の数学的概念が模索されている最中にある<sup class="reference" id="cite_ref-:0_7-1"><a href="#cite_note-:0-7">[5]</a></sup>。ビジネスの現場では多層ニューラルネットワークの応用が盛んであり、「ディープラーニング=<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>」などと解釈される事が多いが、学界ではニューラルネットワーク以外の手法も含めた抽象的な概念として説明される<sup class="reference" id="cite_ref-:0_7-2"><a href="#cite_note-:0-7">[5]</a></sup><sup class="reference" id="cite_ref-:1_8-1"><a href="#cite_note-:1-8">[注釈 3]</a></sup>。
</p>
<h2><span id=".E6.AD.B4.E5.8F.B2"></span><span class="mw-headline" id="歴史">歴史</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=2" title="節を編集: 歴史">編集</a><span class="mw-editsection-bracket">]</span></span></h2>

<p>ディープラーニングは<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>の分野で最初に実現されたため、<a href="/wiki/%E6%AD%B4%E5%8F%B2" title="歴史">歴史</a>は<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>の発展から順次記載する。
</p>
<h3><span id=".E5.89.8D.E5.8F.B2"></span><span class="mw-headline" id="前史">前史</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=3" title="節を編集: 前史">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">「<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF#歴史" title="ニューラルネットワーク">ニューラルネットワーク#歴史</a>」も参照</div>
<p><a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>の構成要素となる<a href="/wiki/%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3" title="パーセプトロン">パーセプトロン</a>が考案されたのは1957年であるが、計算機の性能の大幅な不足や、2層からなる単純パーセプトロンでは<a href="/wiki/%E6%8E%92%E4%BB%96%E7%9A%84%E8%AB%96%E7%90%86%E5%92%8C" title="排他的論理和">排他的論理和</a>の認識ができないなどの欠点があったため、研究が大きく続けられることはなかった<sup class="reference" id="cite_ref-FOOTNOTE小林雅一201392_11-0"><a href="#cite_note-FOOTNOTE小林雅一201392-11">[7]</a></sup>。その後、1980年代より、排他的論理和の問題を扱うことができる3層からなる多層パーセプトロンの学習を可能にする<a href="/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3" title="バックプロパゲーション">バックプロパゲーション</a>が開発されたが、非効率的なメカニズムや、動詞の過去形など複雑な認識ができない（そもそも3層ニューラルネットで任意関数は全て近似可能であり、<a href="/wiki/%E5%A4%A7%E8%84%B3%E6%96%B0%E7%9A%AE%E8%B3%AA" title="大脳新皮質">大脳新皮質</a>がなぜ3層以上存在するのかが不明であった）などの要因により、1990年代後半には沈静化した<sup class="reference" id="cite_ref-12"><a href="#cite_note-12">[8]</a></sup><sup class="reference" id="cite_ref-FOOTNOTE小林雅一201394_13-0"><a href="#cite_note-FOOTNOTE小林雅一201394-13">[9]</a></sup>。
</p>
<h4><span id=".E3.83.8D.E3.82.AA.E3.82.B3.E3.82.B0.E3.83.8B.E3.83.88.E3.83.AD.E3.83.B3.EF.BC.881979.E5.B9.B4.EF.BC.89"></span><span class="mw-headline" id="ネオコグニトロン（1979年）">ネオコグニトロン（1979年）</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=4" title="節を編集: ネオコグニトロン（1979年）">編集</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>ディープラーニングのような多層ニューラルネットワークを志向する先駆的研究として、日本の福島邦彦（NHK放送技術研究所、その後大阪大学基礎工学部生物工学科）によって1979年に発表された<a href="/wiki/%E3%83%8D%E3%82%AA%E3%82%B3%E3%82%B0%E3%83%8B%E3%83%88%E3%83%AD%E3%83%B3" title="ネオコグニトロン">ネオコグニトロン</a><sup class="reference" id="cite_ref-14"><a href="#cite_note-14">[10]</a></sup><sup class="reference" id="cite_ref-15"><a href="#cite_note-15">[11]</a></sup>が挙げられる<sup class="reference" id="cite_ref-16"><a href="#cite_note-16">[12]</a></sup><sup class="reference" id="cite_ref-17"><a href="#cite_note-17">[13]</a></sup>。ネオコグニトロンには自己組織化機能があり、自ら学習することによってパターン認識能力を獲得（概念の形成）していく。応用例として、福島らは手書き文字データベース（ビッグデータ）から自己学習によって手書き文字認識能力（各文字の概念）が獲得されることを実証した。しかし、当時は「手書き文字認識方式の一つ」と誤解され、その重要性についての認識が世間に広がらなかった<sup class="reference" id="cite_ref-FOOTNOTE小林雅一2015107_18-0"><a href="#cite_note-FOOTNOTE小林雅一2015107-18">[14]</a></sup>。この当時はネオコグニトロンを検証する上では<a href="/wiki/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF" title="コンピュータ">デジタルコンピュータ</a>が貧弱過ぎたため、<a href="/wiki/%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2" title="ソフトウェア">ソフトウェア</a>での検証が不可能であり、<a href="/wiki/%E7%B4%A0%E5%AD%90_(%E5%B7%A5%E5%AD%A6)" title="素子 (工学)">回路素子</a>を繋ぎ合わせてネオコグニトロンを実装して検証が行われた。学習方法に<a href="/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3" title="バックプロパゲーション">誤差逆伝播法</a>ではなくadd-if silentを使用している以外は<a href="/wiki/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="畳み込みニューラルネットワーク">畳み込みニューラルネットワーク（CNN）</a>と同じであり、時代を考えると非常に先見性があった。
</p>
<h4><span id="LeNet-5.EF.BC.881998.E5.B9.B4.EF.BC.89"></span><span class="mw-headline" id="LeNet-5（1998年）">LeNet-5（1998年）</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=5" title="節を編集: LeNet-5（1998年）">編集</a><span class="mw-editsection-bracket">]</span></span></h4>
<p><a href="/wiki/1998%E5%B9%B4" title="1998年">1998年</a>には<a href="/wiki/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="畳み込みニューラルネットワーク">畳み込みニューラルネットワーク（CNN）</a>の直系の元祖となるLeNet-5（末尾の数字は5層であることを表す）が提案された。論文の中で、ニューラルネットワークの層構造を板状の図形で図示する方法が初めて用いられた<sup class="reference" id="cite_ref-19"><a href="#cite_note-19">[15]</a></sup>。
</p>
<h3><span id=".E5.A4.9A.E5.B1.A4.E3.83.8B.E3.83.A5.E3.83.BC.E3.83.A9.E3.83.AB.E3.83.8D.E3.83.83.E3.83.88.E3.83.AF.E3.83.BC.E3.82.AF.E3.81.AE.E5.AE.9F.E7.8F.BE.EF.BC.882006_-_2012.E5.B9.B4.EF.BC.89"></span><span class="mw-headline" id="多層ニューラルネットワークの実現（2006_-_2012年）">多層ニューラルネットワークの実現（2006 - 2012年）</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=6" title="節を編集: 多層ニューラルネットワークの実現（2006 - 2012年）">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>初期のディープラーニングはジェフリー・ヒントンによる貢献が大きいため、ニューラルネットワークによる理論実証の過程を記載する。
</p><p>単層<a href="/wiki/%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3" title="パーセプトロン">パーセプトロン</a>の「線型分離不可能な問題」を解けない、という限界は、<a href="/wiki/%E5%A4%9A%E5%B1%A4%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3" title="多層パーセプトロン">多層パーセプトロン</a>の機械学習が<a href="/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3" title="バックプロパゲーション">バックプロパゲーション</a>により実現されたことで、ある程度は解決された。しかし、層数を増やした多層ニューラルネットの学習は、局所最適解や勾配消失などの技術的な問題によって、十分に学習させられず、性能も芳しくないとして、1990年代を中心とした時期には研究なども退潮気味にあった。また、これら理論の不備以前の問題として、発展的な<a href="/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92" title="機械学習">機械学習</a>を行うには<a href="/wiki/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF" title="コンピュータ">コンピュータ</a>の計算性能が大幅に不足しており、大量のデータの入手も難しかったため、研究の大きな障害になっていた。しかし、<a href="/wiki/%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%BC%E3%83%8D%E3%83%83%E3%83%88" title="インターネット">インターネット</a>が広く普及し、コンピュータの性能が向上した<a href="/wiki/2006%E5%B9%B4" title="2006年">2006年</a>に<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>の代表的な研究者である<a href="/wiki/%E3%82%B8%E3%82%A7%E3%83%95%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%92%E3%83%B3%E3%83%88%E3%83%B3" title="ジェフリー・ヒントン">ジェフリー・ヒントン</a>らの研究チームが、<a href="/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E3%83%9E%E3%82%B7%E3%83%B3" title="ボルツマンマシン">制限ボルツマンマシン</a>による<a href="/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%80" title="オートエンコーダ">オートエンコーダ</a>（自己符号化器）の深層化に成功<sup class="reference" id="cite_ref-20"><a href="#cite_note-20">[注釈 5]</a></sup>し、再び注目を集めるようになった。この時発明された手法は積層自己符号化器（スタックトオートエンコーダ）と呼ばれた。この際、発表した論文から、これまでの多層ニューラルネットよりもさらに深いネットワーク構造を意味する、ディープネットワークの用語が定着した。元々はジェフリー・ヒントンらの開発したディープネットワークは層が直列された単純な構造をしていたが、現在のアルゴリズムは複数の分岐やループのある複雑な<a href="/wiki/%E3%82%B0%E3%83%A9%E3%83%95" title="グラフ">グラフ</a>構造を持つ。そのため、基本技術をまとめて複雑なグラフ構造を簡単に実現できるようにした<a href="/wiki/%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA" title="ライブラリ">ライブラリ</a>も公開されている。2012年には物体の認識率を競うILSVRCにおいてジェフリー・ヒントン率いる<a href="/wiki/%E3%83%88%E3%83%AD%E3%83%B3%E3%83%88%E5%A4%A7%E5%AD%A6" title="トロント大学">トロント大学</a>のチームがAlexNetによって従来の手法（エラー率26%）に比べてエラー率17%と実に10%もの劇的な進歩を遂げたことが機械学習の研究者らに衝撃を与えた。その後もILSVRCでは毎年上位はディープラーニングを使ったチームが占めるようになり、エラー率は2014年時点で5%程度にまで改善した<sup class="reference" id="cite_ref-21"><a href="#cite_note-21">[16]</a></sup>。
</p><p>コンピュータのハード性能の急激な進歩、インターネット普及によるデータ収集の容易化、<a href="/wiki/CPU" title="CPU">CPU</a>よりも単純な演算の並列処理に優れた<a href="/wiki/Graphics_Processing_Unit" title="Graphics Processing Unit">GPU</a>の低価格化、また、それらの計算資源の拡張を礎として、画像処理におけるディープラーニングの有用性が競技会で世界的に認知された<a href="/wiki/2012%E5%B9%B4" title="2012年">2012年</a>頃からは急速に研究が活発となり、第三次人工知能ブームが到来したとされている<sup class="reference" id="cite_ref-22"><a href="#cite_note-22">[17]</a></sup>。これ以後は様々な<a href="/wiki/%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2" title="アプリケーションソフトウェア">アプリ</a>に<a href="/wiki/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD" title="人工知能">人工知能</a>が組み込まれ、ユーザーに最適な回答を返す事が出来るようになって行った。
</p>
<h3><span id=".E5.AD.A6.E7.BF.92.E3.83.A2.E3.83.87.E3.83.AB.E3.81.AE.E8.A4.87.E9.9B.91.E5.8C.96.E3.83.BB.E6.95.B0.E5.AD.A6.E7.9A.84.E6.8A.BD.E8.B1.A1.E5.8C.96.E3.81.AE.E6.99.82.E4.BB.A3.EF.BC.882012.E5.B9.B4_-_.E7.8F.BE.E5.9C.A8.EF.BC.89"></span><span class="mw-headline" id="学習モデルの複雑化・数学的抽象化の時代（2012年_-_現在）">学習モデルの複雑化・数学的抽象化の時代（2012年 - 現在）</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=7" title="節を編集: 学習モデルの複雑化・数学的抽象化の時代（2012年 - 現在）">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h2><span id=".E5.88.A9.E7.94.A8"></span><span class="mw-headline" id="利用">利用</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=8" title="節を編集: 利用">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>ディープラーニングは物体認識を中心にさまざまな分野で活用されている。また、Googleをはじめとした多くのIT企業が研究開発に力を入れている。国家の経済成長を大きく左右する技術であるため、国家間の研究開発競争は<a href="/wiki/%E7%B5%8C%E6%B8%88%E6%88%A6%E4%BA%89" title="経済戦争">経済戦争</a>を引き起こしている。
</p><p>Googleの<a href="/wiki/Android_(%E3%82%AA%E3%83%9A%E3%83%AC%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0)" title="Android (オペレーティングシステム)">Android</a> 4.3<sup class="reference" id="cite_ref-23"><a href="#cite_note-23">[18]</a></sup>は、音声認識にディープラーニング技術を活用することで、精度を25から50パーセント向上させた<sup class="reference" id="cite_ref-FOOTNOTE小林雅一201529_24-0"><a href="#cite_note-FOOTNOTE小林雅一201529-24">[19]</a></sup>。2012年、<a href="/wiki/%E3%82%B9%E3%82%BF%E3%83%B3%E3%83%95%E3%82%A9%E3%83%BC%E3%83%89%E5%A4%A7%E5%AD%A6" title="スタンフォード大学">スタンフォード大学</a>との共同研究である<span title="リンク先の項目はまだありません。新規の執筆や他言語版からの翻訳が望まれます。"><a class="new" href="/w/index.php?title=%E3%82%B0%E3%83%BC%E3%82%B0%E3%83%AB%E3%83%BB%E3%83%96%E3%83%AC%E3%82%A4%E3%83%B3&amp;action=edit&amp;redlink=1" title="グーグル・ブレイン (存在しないページ)">グーグル・ブレイン</a><span class="noprint" style="font-size: 0.77em; font-weight: normal;">（<a class="new" href="/w/index.php?title=En:Google_Brain&amp;action=edit&amp;redlink=1" title="En:Google Brain (存在しないページ)">英語版</a>）</span></span>は、1,000の<a href="/wiki/%E3%82%B5%E3%83%BC%E3%83%90%E3%83%BC" title="サーバー">サーバー</a>の16,000のコアを使い、3日間で<a href="/wiki/%E3%83%8D%E3%82%B3" title="ネコ">猫</a>の画像に反応するニューラルネットワークを構築したと発表して話題となった<sup class="reference" id="cite_ref-FOOTNOTE小林雅一201528_25-0"><a href="#cite_note-FOOTNOTE小林雅一201528-25">[20]</a></sup><sup class="reference" id="cite_ref-wired112_26-0"><a href="#cite_note-wired112-26">[21]</a></sup>。この研究では、200ドット四方の1,000万枚の画像を解析させている。ただし、人間の脳には遠く及ばないと指摘されている<sup class="reference" id="cite_ref-pcw632_27-0"><a href="#cite_note-pcw632-27">[22]</a></sup>。GoogleLeNetと呼ばれるチームによる<a href="/wiki/%E3%83%88%E3%83%AD%E3%83%B3%E3%83%88%E5%A4%A7%E5%AD%A6" title="トロント大学">トロント大学</a>との共同研究では、画像の説明文を自動で生成できる「Image to Text」と呼ばれるシステムを開発した。これは、<a href="/wiki/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%83%93%E3%82%B8%E3%83%A7%E3%83%B3" title="コンピュータビジョン">コンピュータビジョン</a>と自然言語処理を組み合わせ、ユーザーがアップロードした画像を認識し、説明文を表示するもの<sup class="reference" id="cite_ref-28"><a href="#cite_note-28">[23]</a></sup><sup class="reference" id="cite_ref-29"><a href="#cite_note-29">[24]</a></sup><sup class="reference" id="cite_ref-30"><a href="#cite_note-30">[25]</a></sup>である。2015年3月、Schroffらは800万人の2億枚の画像を99.6%の精度で判定した（22層）<sup class="reference" id="cite_ref-31"><a href="#cite_note-31">[26]</a></sup>。2016年1月、<a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a>と呼ばれるシステムが中国系フランス人の<a href="/wiki/%E3%83%A8%E3%83%BC%E3%83%AD%E3%83%83%E3%83%91%E7%A2%81%E3%82%B3%E3%83%B3%E3%82%B0%E3%83%AC%E3%82%B9" title="ヨーロッパ碁コングレス">ヨーロッパ囲碁王者</a>である<a href="/wiki/%E6%A8%8A%E9%BA%BE" title="樊麾">樊麾</a>と2015年10月に対局し、5戦全勝の成績を収めていたことが発表された。主に開発に携わったのは2013年にGoogleが買収したDeepMind。囲碁は<a href="/wiki/%E3%83%81%E3%82%A7%E3%82%B9" title="チェス">チェス</a>よりも盤面が広いために打てる手数の多さは比較にならないほどで人間のプロと互角に打てるようになるまでさらに10年はかかるという予測を覆した点と、囲碁に特化したエキスパートマシンではなく汎用的にも用いることができるシステムを使っている点に注目が集まった<sup class="reference" id="cite_ref-32"><a href="#cite_note-32">[27]</a></sup><sup class="reference" id="cite_ref-33"><a href="#cite_note-33">[28]</a></sup>。2016年から2017年にかけては、いずれも世界トップクラスの棋士である<a href="/wiki/%E5%A4%A7%E9%9F%93%E6%B0%91%E5%9B%BD" title="大韓民国">韓国</a>の<a href="/wiki/%E6%9D%8E%E4%B8%96%E3%83%89%E3%83%AB" title="李世ドル">李世乭</a>と<a href="/wiki/%E4%B8%AD%E8%8F%AF%E4%BA%BA%E6%B0%91%E5%85%B1%E5%92%8C%E5%9B%BD" title="中華人民共和国">中国</a>の<a href="/wiki/%E6%9F%AF%E6%BD%94" title="柯潔">柯潔</a>と対戦し、2016年の李世ドルとの5番勝負では4勝1敗、2017年の柯潔との3番勝負では3連勝を収めた<sup class="reference" id="cite_ref-34"><a href="#cite_note-34">[29]</a></sup><sup class="reference" id="cite_ref-35"><a href="#cite_note-35">[30]</a></sup>。
</p>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">「<a href="/wiki/DQN_(%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF)" title="DQN (コンピュータ)">DQN (コンピュータ)</a>」、「<a class="mw-redirect" href="/wiki/Google_DeepMind" title="Google DeepMind">Google DeepMind</a>」、「<a href="/wiki/AlphaGo" title="AlphaGo">AlphaGo</a>」、および「<a href="/wiki/AlphaGo%E5%AF%BE%E6%9D%8E%E4%B8%96%E3%83%89%E3%83%AB" title="AlphaGo対李世ドル">AlphaGo対李世ドル</a>」も参照</div>
<p><a href="/wiki/Facebook" title="Facebook">Facebook</a>は、ユーザーがアップロードした画像を、ディープラーニングによって認識させ、何が写っているかの判別精度を向上させている<sup class="reference" id="cite_ref-FOOTNOTE小林雅一201529_24-1"><a href="#cite_note-FOOTNOTE小林雅一201529-24">[19]</a></sup>。また、人工知能研究ラボを2013年に立ち上げ<sup class="reference" id="cite_ref-36"><a href="#cite_note-36">[31]</a></sup>、その成果としてディープラーニング開発環境を2015年1月16日に<a href="/wiki/%E3%82%AA%E3%83%BC%E3%83%97%E3%83%B3%E3%82%BD%E3%83%BC%E3%82%B9" title="オープンソース">オープンソース</a>で公開した。これは、GPU環境において、従来のコードの23.5倍の速度を実現しており<sup class="reference" id="cite_ref-37"><a href="#cite_note-37">[32]</a></sup>、ディープラーニングの研究開発の促進が期待されている<sup class="reference" id="cite_ref-38"><a href="#cite_note-38">[33]</a></sup>。
</p><p><a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>によるディープラーニングを使った<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3" title="ニューラル機械翻訳">ニューラル機械翻訳</a>（NMT）が登場したことで、翻訳の品質が大幅に向上した<sup class="reference" id="cite_ref-nmt001_39-0"><a href="#cite_note-nmt001-39">[34]</a></sup>。
</p><p>自動運転車の障害物センサーにも使われている<sup class="reference" id="cite_ref-40"><a href="#cite_note-40">[35]</a></sup>。
</p><p>利点が多い一方で、<a href="/wiki/%E5%80%AB%E7%90%86" title="倫理">倫理</a>的な問題や<a href="/wiki/%E7%8A%AF%E7%BD%AA" title="犯罪">犯罪</a>も発生している。例えば、中国では<a href="/wiki/%E5%A4%A9%E7%B6%B2" title="天網">天網</a>に代表されるようにディープラーニングが国民に対する当局の監視強化を目的に急速に普及しており<sup class="reference" id="cite_ref-41"><a href="#cite_note-41">[36]</a></sup><sup class="reference" id="cite_ref-42"><a href="#cite_note-42">[37]</a></sup><sup class="reference" id="cite_ref-43"><a href="#cite_note-43">[38]</a></sup>、世界のディープラーニング用サーバーの4分の3を占めているとされる<sup class="reference" id="cite_ref-44"><a href="#cite_note-44">[39]</a></sup>。米国政府によれば2013年からディープラーニングに関する論文数では中国が米国を超えて世界一となっている<sup class="reference" id="cite_ref-45"><a href="#cite_note-45">[40]</a></sup>。ヒントンらと並んで「ディープラーニングの父」と呼ばれている<a href="/wiki/%E3%83%A8%E3%82%B7%E3%83%A5%E3%82%A2%E3%83%BB%E3%83%99%E3%83%B3%E3%82%B8%E3%82%AA" title="ヨシュア・ベンジオ">ヨシュア・ベンジオ</a>は中国が市民の監視や独裁政治の強化に人工知能を利用していることに警鐘を鳴らした<sup class="reference" id="cite_ref-46"><a href="#cite_note-46">[41]</a></sup><sup class="reference" id="cite_ref-47"><a href="#cite_note-47">[42]</a></sup>。また、<a href="/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%95%E3%82%A7%E3%82%A4%E3%82%AF" title="ディープフェイク">ディープフェイク</a>という、本物と区別の付かない偽画像生成技術が登場し、特定の<a href="/wiki/%E3%82%BB%E3%83%AC%E3%83%96%E3%83%AA%E3%83%86%E3%82%A3" title="セレブリティ">有名人</a>の顔や声を使って事実と異なる発言や<a href="/wiki/%E3%83%9D%E3%83%AB%E3%83%8E" title="ポルノ">ポルノ</a>（ディープフェイクポルノと呼ばれる）を収めた<a href="/wiki/%E5%8B%95%E7%94%BB" title="動画">動画</a>が多数流通するようになってからは、重大な<a href="/wiki/%E5%90%8D%E8%AA%89%E6%AF%80%E6%90%8D" title="名誉毀損">名誉毀損</a>や<a href="/wiki/%E4%BA%BA%E6%A0%BC%E6%A8%A9" title="人格権">人格権</a>の侵害の可能性があることから、<a href="/wiki/%E8%AD%A6%E5%AF%9F" title="警察">警察</a>が作成者やサイト運営者の<a href="/wiki/%E6%91%98%E7%99%BA" title="摘発">摘発</a>に動いている<sup class="reference" id="cite_ref-48"><a href="#cite_note-48">[43]</a></sup>。さらに、偽の画像や音声を用いて様々な無人制御システムを撹乱する攻撃が想定されるため、被害を未然に防ぐ観点から対策が行われている<sup class="reference" id="cite_ref-49"><a href="#cite_note-49">[44]</a></sup>。
</p>
<h2><span id=".E3.83.8D.E3.83.83.E3.83.88.E3.83.AF.E3.83.BC.E3.82.AF.E3.83.A2.E3.83.87.E3.83.AB"></span><span class="mw-headline" id="ネットワークモデル">ネットワークモデル</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=9" title="節を編集: ネットワークモデル">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>ネットワークモデルは現在も盛んに研究されており、毎年新しいものが提案されている。
</p>
<h3><span id=".E7.95.B3.E3.81.BF.E8.BE.BC.E3.81.BF.E3.83.8B.E3.83.A5.E3.83.BC.E3.83.A9.E3.83.AB.E3.83.8D.E3.83.83.E3.83.88.E3.83.AF.E3.83.BC.E3.82.AF"></span><span class="mw-headline" id="畳み込みニューラルネットワーク">畳み込みニューラルネットワーク</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=10" title="節を編集: 畳み込みニューラルネットワーク">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="畳み込みニューラルネットワーク">畳み込みニューラルネットワーク</a> (Convolutional Neural Networks: CNN) とは、全結合していない順伝播型ニューラルネットワークの一種。特に2次元の畳込みニューラルネットワークは人間の視覚野のニューロンの結合と似たニューラルネットワークであり、人間の認知とよく似た学習が行われることが期待される。結合がスパース（疎）であるため、全結合しているニューラルネットワークに比べて学習が高速である。
</p><p>1979年に福島邦彦が発表した<a href="/wiki/%E3%83%8D%E3%82%AA%E3%82%B3%E3%82%B0%E3%83%8B%E3%83%88%E3%83%AD%E3%83%B3" title="ネオコグニトロン">ネオコグニトロン</a>から発展し、1988年にHomma Toshiteruらが音素の認識に<sup class="reference" id="cite_ref-50"><a href="#cite_note-50">[45]</a></sup>、1989年にYann LeCunらが文字画像の認識に使用し<sup class="reference" id="cite_ref-51"><a href="#cite_note-51">[46]</a></sup><sup class="reference" id="cite_ref-52"><a href="#cite_note-52">[47]</a></sup>、1998年にLeCunらが発表したLeNet-5へと続き、2012年にILSVRCでの物体カテゴリ認識で優勝したAlexNetも深層畳み込みニューラルネットワークである<sup class="reference" id="cite_ref-53"><a href="#cite_note-53">[48]</a></sup>。ネオコグニトロンの時から深層であったが、近年は深層であることを強調するため、深層が頭につき、深層畳み込みニューラルネットワークと呼ばれることもある。自然言語処理に対する応用もなされはじめた。
</p>
<h3><span id=".E3.82.B9.E3.82.BF.E3.83.83.E3.82.AF.E3.83.88.E3.82.AA.E3.83.BC.E3.83.88.E3.82.A8.E3.83.B3.E3.82.B3.E3.83.BC.E3.83.80"></span><span class="mw-headline" id="スタックトオートエンコーダ">スタックトオートエンコーダ</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=11" title="節を編集: スタックトオートエンコーダ">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>まず3層の<a href="/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%82%A8%E3%83%B3%E3%82%B3%E3%83%BC%E3%83%80" title="オートエンコーダ">オートエンコーダ</a>で学習を行い、学習が完了したら次の層（4層目）をオートエンコーダとして学習する。これを必要な分だけ繰り返していき、最後に全層の学習を行う。事前学習とも呼ばれる。類似技術にディープビリーフネットワーク、ディープボルツマンマシンなどがある。
</p>
<h3><span class="mw-headline" id="Residual_network">Residual network</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=12" title="節を編集: Residual network">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>入力データを出力に変える変換を学習するのではなく、<a href="/wiki/%E6%AE%8B%E5%B7%AE" title="残差">残差</a>を学習する。通常の多層ニューラルネットより<a href="/wiki/%E5%8B%BE%E9%85%8D" title="勾配">勾配</a>消失がおきにくく、はるかに多層化できる。実験的には1000層まで学習されたものもある。欠点としては、入力次元数と出力次元数を変えることができない。
</p>
<h3><span id=".E6.95.B5.E5.AF.BE.E7.9A.84.E7.94.9F.E6.88.90.E3.83.8D.E3.83.83.E3.83.88.E3.83.AF.E3.83.BC.E3.82.AF"></span><span class="mw-headline" id="敵対的生成ネットワーク">敵対的生成ネットワーク</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=13" title="節を編集: 敵対的生成ネットワーク">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">詳細は「<a href="/wiki/%E6%95%B5%E5%AF%BE%E7%9A%84%E7%94%9F%E6%88%90%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="敵対的生成ネットワーク"> 敵対的生成ネットワーク</a>」を参照</div>
<p>2つのネットワークが相反した目的のもとに学習するネットワークモデル。Discriminatorが損失関数の役目を担う。二乗誤差最小化などでは、ピークが一つしか無いことを仮定しているが、discriminatorはニューラルネットであるのでピークを複数持つ確率分布を近似でき、より一般の確率分布を扱うことができる。
</p>
<h3><span id=".E3.83.9C.E3.83.AB.E3.83.84.E3.83.9E.E3.83.B3.E3.83.9E.E3.82.B7.E3.83.B3"></span><span class="mw-headline" id="ボルツマンマシン">ボルツマンマシン</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=14" title="節を編集: ボルツマンマシン">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">詳細は「<a href="/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E3%83%9E%E3%82%B7%E3%83%B3" title="ボルツマンマシン">ボルツマンマシン</a>」を参照</div>
<p>統計的な変動をもちいた<a href="/wiki/%E3%83%9B%E3%83%83%E3%83%97%E3%83%95%E3%82%A3%E3%83%BC%E3%83%AB%E3%83%89%E3%83%BB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ホップフィールド・ネットワーク">ホップフィールド・ネットワーク</a>の一種。
</p>
<h4><span id=".E5.88.B6.E9.99.90.E3.83.9C.E3.83.AB.E3.83.84.E3.83.9E.E3.83.B3.E3.83.9E.E3.82.B7.E3.83.B3"></span><span class="mw-headline" id="制限ボルツマンマシン">制限ボルツマンマシン</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=15" title="節を編集: 制限ボルツマンマシン">編集</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>同一層間では接続を持たないボルツマンマシン。
</p>
<h3><span id=".E5.9B.9E.E5.B8.B0.E5.9E.8B.E3.83.8B.E3.83.A5.E3.83.BC.E3.83.A9.E3.83.AB.E3.83.8D.E3.83.83.E3.83.88.E3.83.AF.E3.83.BC.E3.82.AF"></span><span class="mw-headline" id="回帰型ニューラルネットワーク">回帰型ニューラルネットワーク</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=16" title="節を編集: 回帰型ニューラルネットワーク">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">詳細は「<a href="/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="回帰型ニューラルネットワーク">回帰型ニューラルネットワーク</a>」を参照</div>
<p><a href="/wiki/%E5%9B%9E%E5%B8%B0%E5%9E%8B%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="回帰型ニューラルネットワーク">回帰型ニューラルネットワーク</a> (Recurrent Neural Network: RNN) とは、有向<a href="/wiki/%E9%96%89%E8%B7%AF" title="閉路">閉路</a>を持つニューラルネットワークのこと。それ以前の入力によって変化する<a href="/wiki/%E7%8A%B6%E6%85%8B" title="状態">状態</a>を保持する（<a href="/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%83%9E%E3%83%88%E3%83%B3" title="オートマトン">オートマトン</a>）。動画像、音声、言語など、入力データの順序によって出力が変わる場合に有効である。また、順伝播型ニューラルネットワークでは、近似できるピーク数が中間層の素子数に依存するのに対して、回帰型ニューラルネットワークでは無限の周期性を持つ関数を近似することが可能である。
</p><p>1980年代から研究が始まり、1982年に発表された<a href="/wiki/%E3%83%9B%E3%83%83%E3%83%97%E3%83%95%E3%82%A3%E3%83%BC%E3%83%AB%E3%83%89%E3%83%BB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ホップフィールド・ネットワーク">ホップフィールド・ネットワーク</a>が初期の研究。その後ElmanネットワークやJordanネットワークが発表され、1997年にS. HochreiterおよびJ. Schmidhuberらが<a class="mw-redirect" href="/wiki/LSTM" title="LSTM">LSTM</a>ネットワーク（<a href="/wiki/%E9%95%B7%E3%83%BB%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6" title="長・短期記憶">長・短期記憶</a>、Long short-term memory）を発表した。
</p>
<h2><span id=".E7.89.B9.E6.9C.89.E3.81.AE.E5.95.8F.E9.A1.8C"></span><span class="mw-headline" id="特有の問題">特有の問題</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=17" title="節を編集: 特有の問題">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span id=".E5.8B.BE.E9.85.8D.E6.B6.88.E5.A4.B1.E5.95.8F.E9.A1.8C"></span><span class="mw-headline" id="勾配消失問題">勾配消失問題</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=18" title="節を編集: 勾配消失問題">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>確率的勾配法は誤差から勾配を計算して中間層の重みを修正するが、<a href="/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0" title="シグモイド関数">シグモイド関数</a>などは見てすぐにわかる通り、勾配が0に近い領域が存在する。偶然その領域に進むと勾配が0に近くなり、重みがほぼ修正されなくなる。多層NNでは一か所でも勾配が0に近い層が存在すると、それより下の層の勾配も全て0に近くなるため、確率的には層数が増えるほど学習が難しくなる。詳しくは<a href="/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3" title="バックプロパゲーション">バックプロパゲーション</a>、<a href="/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0" title="活性化関数">活性化関数</a>も参照のこと。
</p>
<h3><span id=".E9.81.8E.E5.AD.A6.E7.BF.92"></span><span class="mw-headline" id="過学習">過学習</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=19" title="節を編集: 過学習">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>トレーニングデータでは高識別率を達成しながら、テストデータでは識別率が低い現象。<a href="/wiki/%E9%81%8E%E5%89%B0%E9%81%A9%E5%90%88" title="過剰適合">過剰適合</a>も参照のこと。
</p>
<h3><span id=".E5.B1.80.E6.89.80.E6.9C.80.E9.81.A9.E8.A7.A3.E3.81.B8.E3.81.AE.E3.83.88.E3.83.A9.E3.83.83.E3.83.97"></span><span class="mw-headline" id="局所最適解へのトラップ">局所最適解へのトラップ</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=20" title="節を編集: 局所最適解へのトラップ">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>学習が、大域的な最適解ではなく、局所的には適した解へと収束し、抜け出せなくなること。
</p>
<h2><span id=".E3.83.86.E3.82.AF.E3.83.8B.E3.83.83.E3.82.AF"></span><span class="mw-headline" id="テクニック">テクニック</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=21" title="節を編集: テクニック">編集</a><span class="mw-editsection-bracket">]</span></span></h2>

<h3><span id=".E3.83.87.E3.83.BC.E3.82.BF.E6.8B.A1.E5.BC.B5"></span><span class="mw-headline" id="データ拡張">データ拡張</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=22" title="節を編集: データ拡張">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>深層学習以外でも広く使われているが、入力データが画像など、どのようなテストデータが来るかあらかじめある程度の想定（モデル化）ができる場合は、たとえば画像の回転や引き延ばしを行うことで入力データ数を増やすことも昔から行われている。
</p>
<h3><span id=".E6.B4.BB.E6.80.A7.E5.8C.96.E9.96.A2.E6.95.B0"></span><span class="mw-headline" id="活性化関数">活性化関数</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=23" title="節を編集: 活性化関数">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>古くからニューラルネットワークにおいては<a href="/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89" title="シグモイド">シグモイド</a>関数がよく使われていたが、勾配消失問題などにより、近年では別の関数が使われるようになった。詳しくは<a href="/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0" title="活性化関数">活性化関数</a>を参照。
</p>
<h4><span class="mw-headline" id="ReLU">ReLU</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=24" title="節を編集: ReLU">編集</a><span class="mw-editsection-bracket">]</span></span></h4>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">詳細は「<a href="/wiki/%E6%AD%A3%E8%A6%8F%E5%8C%96%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0" title="正規化線形関数">正規化線形関数</a>」を参照</div>
<p><a href="/wiki/%E6%AD%A3%E8%A6%8F%E5%8C%96%E7%B7%9A%E5%BD%A2%E9%96%A2%E6%95%B0" title="正規化線形関数">ReLU</a>（rectified linear unit <a href="/wiki/%E3%83%A9%E3%83%B3%E3%83%97%E9%96%A2%E6%95%B0" title="ランプ関数">ランプ関数</a>とも呼ばれる）
</p>
<dl><dd>&lt;math&gt;f(x) = \max(0, x)&lt;/math&gt;</dd></dl>
<p>出力が0.0 - 1.0に規格化されないため勾配消失問題が起きにくく、またシグモイド関数に比べると単純であるために計算量が小さく学習が速く進む等のメリットがある<sup class="reference" id="cite_ref-54"><a href="#cite_note-54">[49]</a></sup>。
</p>
<h4><span class="mw-headline" id="maxout">maxout</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=25" title="節を編集: maxout">編集</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>複数の次元の最大値を出力する関数。CNNのプーリングと同じ計算である。高性能と言われるが、性質上、次元が減少する。<a href="/wiki/%E7%89%B9%E5%BE%B4%E9%81%B8%E6%8A%9E" title="特徴選択">特徴選択</a>も兼ねていると言える。
</p>
<h3><span id=".E3.83.89.E3.83.AD.E3.83.83.E3.83.97.E3.82.A2.E3.82.A6.E3.83.88"></span><span class="mw-headline" id="ドロップアウト">ドロップアウト</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=26" title="節を編集: ドロップアウト">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/%E3%83%89%E3%83%AD%E3%83%83%E3%83%97%E3%82%A2%E3%82%A6%E3%83%88" title="ドロップアウト">ドロップアウト</a>はランダムに任意のニューロン（次元）を何割か無視してしまう技術である。入力データを増やせずとも、次元を減らすことで解の<a href="/wiki/%E6%9C%89%E6%84%8F" title="有意">有意</a>性を上げることができる。ドロップアウトして得た学習結果は、テスト時には同時に使用し、結果は平均して用いる。これは<a class="mw-redirect" href="/wiki/Random_forest" title="Random forest">Random forest</a>と同様、検出率の低い識別器でも並列化することで<a class="new" href="/w/index.php?title=%E4%BF%A1%E9%A0%BC%E5%BA%A6&amp;action=edit&amp;redlink=1" title="信頼度 (存在しないページ)">信頼度</a>を上げることができるためである。
</p>
<h3><span id=".E3.82.B9.E3.83.91.E3.83.BC.E3.82.B9.E3.82.B3.E3.83.BC.E3.83.87.E3.82.A3.E3.83.B3.E3.82.B0"></span><span class="mw-headline" id="スパースコーディング">スパースコーディング</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=27" title="節を編集: スパースコーディング">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/%E3%83%A9%E3%83%83%E3%82%BD%E5%9B%9E%E5%B8%B0" title="ラッソ回帰">ラッソ回帰</a>とも呼ばれる。辞書行列と係数行列の内積（<a class="mw-redirect" href="/wiki/%E7%B7%9A%E5%BD%A2%E7%B5%90%E5%90%88" title="線形結合">線形結合</a>）で入力データ(列ベクトル)を近似するとき、係数行列は<a href="/wiki/%E7%96%8E%E8%A1%8C%E5%88%97" title="疎行列">疎行列</a>（非零の要素が僅かしかない行列）になる。L1<a href="/wiki/%E6%AD%A3%E5%89%87%E5%8C%96" title="正則化">正則化</a>のこと。
</p>
<div class="rellink" style="margin-bottom: 0.5em; padding-left: 2em; font-style: italic;">「<a href="/wiki/%E6%AD%A3%E5%89%87%E5%8C%96" title="正則化">正則化</a>」、「<a href="/wiki/%E9%80%86%E5%95%8F%E9%A1%8C" title="逆問題">逆問題</a>」、および「<a class="mw-redirect" href="/wiki/%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB" title="回帰モデル">回帰モデル</a>」も参照</div>
<h3><span id=".E3.83.90.E3.83.83.E3.83.81.E6.AD.A3.E5.89.87.E5.8C.96"></span><span class="mw-headline" id="バッチ正則化">バッチ正則化</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=28" title="節を編集: バッチ正則化">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>バッチ学習を行う際に、バッチ正則化層を設け、白色化 (入力データを平均 0、分散 1 に正則化) する。従来は、内部共変量シフト (internal covariance shift) を抑えることで、学習が効率的に進むとされていたが、現在では単に内部共変量シフトだけによるものではないと考えられている<sup class="reference" id="cite_ref-55"><a href="#cite_note-55">[50]</a></sup><sup class="reference" id="cite_ref-56"><a href="#cite_note-56">[51]</a></sup><sup class="reference" id="cite_ref-57"><a href="#cite_note-57">[52]</a></sup>。
</p>
<h3><span id=".E3.83.9F.E3.83.8B.E3.83.90.E3.83.83.E3.83.81.E6.B3.95"></span><span class="mw-headline" id="ミニバッチ法">ミニバッチ法</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=29" title="節を編集: ミニバッチ法">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h3><span id=".E8.92.B8.E7.95.99"></span><span class="mw-headline" id="蒸留">蒸留</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=30" title="節を編集: 蒸留">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h3><span id=".E4.BA.8B.E5.89.8D.E5.AD.A6.E7.BF.92_.28Pre-training.29"></span><span class="mw-headline" id="事前学習_(Pre-training)">事前学習 (Pre-training)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=31" title="節を編集: 事前学習 (Pre-training)">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h3><span class="mw-headline" id="AdaGrad">AdaGrad</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=32" title="節を編集: AdaGrad">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h3><span class="mw-headline" id="Adam">Adam</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=33" title="節を編集: Adam">編集</a><span class="mw-editsection-bracket">]</span></span></h3>

<h2><span id=".E3.83.A9.E3.82.A4.E3.83.96.E3.83.A9.E3.83.AA"></span><span class="mw-headline" id="ライブラリ">ライブラリ</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=34" title="節を編集: ライブラリ">編集</a><span class="mw-editsection-bracket">]</span></span></h2>

<ul><li><a href="/wiki/Caffe" title="Caffe">Caffe</a> - <a href="/wiki/Python" title="Python">Python</a>, <a href="/wiki/C%2B%2B" title="C++">C++</a></li>
<li><a class="new" href="/w/index.php?title=Torch&amp;action=edit&amp;redlink=1" title="Torch (存在しないページ)">torch</a> - <a href="/wiki/Lua" title="Lua">Lua</a></li>
<li><a class="new" href="/w/index.php?title=Theano&amp;action=edit&amp;redlink=1" title="Theano (存在しないページ)">Theano</a> - Python。関数型言語。並列化に特化し、GPUのコードが自動的に生成される。</li>
<li>Pylearn2 - Python</li>
<li>Blocks - Python</li>
<li><a href="/wiki/Keras" title="Keras">Keras</a> - Python。TensorFlowのラッパー。Theanoでも動作可能。</li>
<li>Lasagne - Python</li>
<li>deepy - Python</li>
<li><a class="external text" href="https://developer.nvidia.com/cudnn" rel="nofollow">cuDNN</a> - <a href="/wiki/NVIDIA" title="NVIDIA">NVIDIA</a>が提供する<a href="/wiki/CUDA" title="CUDA">CUDA</a>ベース (GPUベース) のDNN用プリミティブライブラリ。</li>
<li><a href="/wiki/Deeplearning4j" title="Deeplearning4j">Deeplearning4j</a> - <a href="/wiki/Java" title="Java">Java</a>、<a href="/wiki/Scala" title="Scala">Scala</a>が使用されている。</li>
<li>EBlearn - C++で書かれているCNN用ライブラリ。</li>
<li><a class="external text" href="https://code.google.com/archive/p/cuda-convnet/" rel="nofollow">cuda-convnet</a> - C++/CUDA実装のCNN。基本的な機能はEBlearnと同じ。</li>
<li><a href="/wiki/Chainer" title="Chainer">Chainer</a> - Python</li>
<li><a href="/wiki/TensorFlow" title="TensorFlow">TensorFlow</a> - Python, C++</li>
<li>ReNom - Python</li>
<li><a href="/wiki/PyTorch" title="PyTorch">PyTorch</a></li>
<li><a href="/wiki/Microsoft_Cognitive_Toolkit" title="Microsoft Cognitive Toolkit">Microsoft Cognitive Toolkit</a> - Python, C++, C#。以前はCNTKと呼ばれていた。</li>
<li><a href="/wiki/DyNet" title="DyNet">DyNet</a> - Python, C++</li></ul>
<h2><span id=".E8.84.9A.E6.B3.A8"></span><span class="mw-headline" id="脚注">脚注</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=35" title="節を編集: 脚注">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="noprint" style="float:right; font-size:90%;"><tbody><tr><td>[<a href="/wiki/%E3%83%98%E3%83%AB%E3%83%97:%E8%84%9A%E6%B3%A8/%E8%AA%AD%E8%80%85%E5%90%91%E3%81%91" title="ヘルプ:脚注/読者向け"><span title="この欄の操作法">脚注の使い方</span></a>]</td></tr></tbody></table>
<h3><span id=".E6.B3.A8.E9.87.88"></span><span class="mw-headline" id="注釈">注釈</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=36" title="節を編集: 注釈">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="reflist" style="list-style-type: decimal;">
<div class="mw-references-wrap"><ol class="references">
<li id="cite_note-:0-2">^ <a href="#cite_ref-:0_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_2-1"><sup><i><b>b</b></i></sup></a> <span class="reference-text">ディープラーニング(深層学習)の大家として世界的に知られるIan Goodfellow，Yoshua Bengio，Aaron Courvilleが著した"Deep Learning"という教科書のIntroductionの第４パラグラフ（pp.1-2）におけるディープラーニングの定義では、ニューラルネットワークについて全く触れられておらず、「概念の階層により、コンピューターは、単純な概念から複雑な概念を構築することにより、複雑な概念を学習できます。これらの概念がどのように相互に構築されているかを示すグラフを描くと、グラフは深く、多くの層があります。このため、このアプローチをAIディープラーニングと呼びます。」と概念の階層構造により定義している。</span>
</li>
<li id="cite_note-4"><b><a href="#cite_ref-4">^</a></b> <span class="reference-text">2層なら単純<a href="/wiki/%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3" title="パーセプトロン">パーセプトロン</a>。3層なら階層型ニューラルネット。これらと比較して深い層の階層型ニューラルネットを、深層（階層型）ニューラルネットと呼ぶ。</span>
</li>
<li id="cite_note-:1-8">^ <a href="#cite_ref-:1_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_8-1"><sup><i><b>b</b></i></sup></a> <span class="reference-text">学界は<a href="/wiki/%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD" title="人工知能">人工知能</a>が有用であればどのような実現方法でも良いとの認識である。従って、学界は計算機における<a href="/wiki/%E4%BA%BA%E9%96%93" title="人間">人間</a>の<a href="/wiki/%E8%84%B3" title="脳">脳</a>の再現だけを目指しているわけではない。また、<a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a>は<a href="/wiki/%E4%BA%BA%E9%96%93" title="人間">人間</a>の<a href="/wiki/%E8%84%B3%E7%A5%9E%E7%B5%8C" title="脳神経">脳神経</a>の<a href="/wiki/%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ネットワーク">ネットワーク</a>構造に着想を得て研究が始められただけであり、その後は一部の研究事例を除いて<a href="/wiki/%E4%BA%BA%E9%96%93" title="人間">人間</a>の<a href="/wiki/%E8%84%B3" title="脳">脳</a>とは無関係に多様な方法で理論拡張が行われ続けている。</span>
</li>
<li id="cite_note-9"><b><a href="#cite_ref-9">^</a></b> <span class="reference-text">2層なら単純<a href="/wiki/%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3" title="パーセプトロン">パーセプトロン</a>。3層なら階層型ニューラルネット。これらと比較して深い層の階層型ニューラルネットを、深層（階層型）ニューラルネットと呼ぶ。</span>
</li>
<li id="cite_note-20"><b><a href="#cite_ref-20">^</a></b> <span class="reference-text">積層自己符号化器（スタックドオートエンコーダ）と呼ばれる手法</span>
</li>
</ol></div></div>
<h3><span id=".E5.87.BA.E5.85.B8"></span><span class="mw-headline" id="出典">出典</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=37" title="節を編集: 出典">編集</a><span class="mw-editsection-bracket">]</span></span></h3>
<div class="reflist" style="-moz-column-count:2; -webkit-column-count:2; column-count:2; -moz-column-width: 20em; -webkit-column-width: 20em; column-width: 20em; list-style-type: decimal;">
<div class="mw-references-wrap mw-references-columns"><ol class="references">
<li id="cite_note-:1-1">^ <a href="#cite_ref-:1_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_1-1"><sup><i><b>b</b></i></sup></a> <span class="reference-text"><cite class="citation web" style="font-style:normal">Ian Goodfellow and Yoshua Bengio and Aaron Courville. “<a class="external text" href="https://www.deeplearningbook.org/contents/intro.html" rel="nofollow">Deep Learning</a>” (English).   マサチューセッツ工科大学出版局. <span title="">2021年2月4日</span>閲覧。</cite></span>
</li>
<li id="cite_note-asou-3">^ <a href="#cite_ref-asou_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-asou_3-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-asou_3-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-asou_3-3"><sup><i><b>d</b></i></sup></a> <span class="reference-text"><cite class="citation book" id="Reference-麻生英樹_他、監修:_人工知能学会-2015" style="font-style:normal">麻生英樹 他、監修: 人工知能学会「深層学習手法の全体像」『深層学習』近代科学社、2015年、xiv。<style data-mw-deduplicate="TemplateStyles:r2293413">/*
スタイルシート[[:モジュール:Citation/CS1/styles.css]] (rev 2293413) の処理でエラーが発生しました：• 29行目14文字目のプロパティ⧼code⧽background⧼/code⧽に、不正またはサポートされていない値が指定されています。
• 38行目14文字目のプロパティ⧼code⧽background⧼/code⧽に、不正またはサポートされていない値が指定されています。
• 45行目14文字目のプロパティ⧼code⧽background⧼/code⧽に、不正またはサポートされていない値が指定されています。
• 66行目14文字目のプロパティ⧼code⧽background⧼/code⧽に、不正またはサポートされていない値が指定されています。
*/
.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><a href="/wiki/ISBN" title="ISBN">ISBN</a> <a href="/wiki/%E7%89%B9%E5%88%A5:%E6%96%87%E7%8C%AE%E8%B3%87%E6%96%99/9784764904873" title="特別:文献資料/9784764904873">9784764904873</a>。</cite></span>
</li>
<li id="cite_note-5"><b><a href="#cite_ref-5">^</a></b> <span class="reference-text">深層学習 人工知能学会 深層学習手法の全体像xiii</span>
</li>
<li id="cite_note-Okatani_DL-6">^ <a href="#cite_ref-Okatani_DL_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Okatani_DL_6-1"><sup><i><b>b</b></i></sup></a> <span class="reference-text">岡谷貴之 深層学習 (機械学習プロフェッショナルシリーズ)、2015年4月8日、まえがき、ISBN 978-4061529021</span>
</li>
<li id="cite_note-:0-7">^ <a href="#cite_ref-:0_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_7-2"><sup><i><b>c</b></i></sup></a> <span class="reference-text"><cite class="citation web" style="font-style:normal">Ian Goodfellow and Yoshua Bengio and Aaron Courville. “<a class="external text" href="https://www.deeplearningbook.org/contents/intro.html" rel="nofollow">Deep Learning</a>”.   An MIT Press book. p. 14. <span title="">2021年2月3日</span>閲覧。</cite></span>
</li>
<li id="cite_note-10"><b><a href="#cite_ref-10">^</a></b> <span class="reference-text">深層学習 人工知能学会 深層学習手法の全体像xiii</span>
</li>
<li id="cite_note-FOOTNOTE小林雅一201392-11"><b><a href="#cite_ref-FOOTNOTE小林雅一201392_11-0">^</a></b> <span class="reference-text"><a href="#CITEREF小林雅一2013">小林雅一 2013</a>, p. 92.</span>
</li>
<li id="cite_note-12"><b><a href="#cite_ref-12">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://wirelesswire.jp/2015/05/30505/" rel="nofollow">ディープラーニングはビジネスにどう使えるか?</a>”.   WirelessWire News (2015年5月20日). <span title="">2015年5月21日</span>閲覧。</cite></span>
</li>
<li id="cite_note-FOOTNOTE小林雅一201394-13"><b><a href="#cite_ref-FOOTNOTE小林雅一201394_13-0">^</a></b> <span class="reference-text"><a href="#CITEREF小林雅一2013">小林雅一 2013</a>, p. 94.</span>
</li>
<li id="cite_note-14"><b><a href="#cite_ref-14">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://dbnst.nii.ac.jp/pro/detail/498" rel="nofollow">ネオコグニトロン</a>”. <span title="">2015年6月30日</span>閲覧。</cite></span>
</li>
<li id="cite_note-15"><b><a href="#cite_ref-15">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://search.ieice.org/bin/summary.php?id=j62-a_10_658&amp;category=A&amp;lang=J&amp;year=1979&amp;abst=" rel="nofollow">位置ずれに影響されないパターン認識機構の神経回路のモデル --- ネオコグニトロン ---</a>”.   電子通信学会論文誌A (1979年10月1日). <span title="">2017年8月16日</span>閲覧。</cite></span>
</li>
<li id="cite_note-16"><b><a href="#cite_ref-16">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://techon.nikkeibp.co.jp/article/INTERVIEW/20150521/419523/?ST=tomict" rel="nofollow">「ネオコグニトロンはまだ進化する」、画像向けディープラーニング「CNN」の父に聞く</a>” (2015年5月22日). <span title="">2015年9月3日</span>閲覧。</cite></span>
</li>
<li id="cite_note-17"><b><a href="#cite_ref-17">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://www.4gamer.net/games/999/G999902/20150829007/" rel="nofollow">［CEDEC 2015］画像認識ではすでに人間を凌駕。ディープラーニングが日本を再生する</a>”.   4gamer (2015年8月29日). <span title="">2015年9月1日</span>閲覧。</cite></span>
</li>
<li id="cite_note-FOOTNOTE小林雅一2015107-18"><b><a href="#cite_ref-FOOTNOTE小林雅一2015107_18-0">^</a></b> <span class="reference-text"><a href="#CITEREF小林雅一2015">小林雅一 2015</a>, p. 107.</span>
</li>
<li id="cite_note-19"><b><a href="#cite_ref-19">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://yann.lecun.com/exdb/lenet/" rel="nofollow">MNIST Demos on Yann LeCun's website</a>”. <i>yann.lecun.com</i>. <span title="">2021年3月31日</span>閲覧。</cite></span>
</li>
<li id="cite_note-21"><b><a href="#cite_ref-21">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">浅川 直輝 (2014年10月1日). “<a class="external text" href="https://tech.nikkeibp.co.jp/it/atcl/column/14/090100053/091800010/" rel="nofollow">［脳に挑む人工知能1］驚異のディープラーニング、その原型は日本人が開発</a>”.   日経 xTECH（クロステック）. <span title="">2019年12月20日</span>閲覧。</cite></span>
</li>
<li id="cite_note-22"><b><a href="#cite_ref-22">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://enterprisezine.jp/article/detail/6471?p=2" rel="nofollow">【第四回】今、最も熱いディープラーニングを体験してみよう（2ページ）</a>”.   エンタープライズ (2015年1月14日). <span title="">2015年5月30日</span>閲覧。</cite></span>
</li>
<li id="cite_note-23"><b><a href="#cite_ref-23">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://ascii.jp/elem/000/000/991/991583/" rel="nofollow">Googleのディープラーニングはレトロゲームを自分で学習してプレイする</a>”.   ascii×デジタル (2015年3月21日). <span title="">2015年5月21日</span>閲覧。</cite></span>
</li>
<li id="cite_note-FOOTNOTE小林雅一201529-24">^ <a href="#cite_ref-FOOTNOTE小林雅一201529_24-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-FOOTNOTE小林雅一201529_24-1"><sup><i><b>b</b></i></sup></a> <span class="reference-text"><a href="#CITEREF小林雅一2015">小林雅一 2015</a>, p. 29.</span>
</li>
<li id="cite_note-FOOTNOTE小林雅一201528-25"><b><a href="#cite_ref-FOOTNOTE小林雅一201528_25-0">^</a></b> <span class="reference-text"><a href="#CITEREF小林雅一2015">小林雅一 2015</a>, p. 28.</span>
</li>
<li id="cite_note-wired112-26"><b><a href="#cite_ref-wired112_26-0">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://wired.jp/2014/11/20/google-image-recognition/" rel="nofollow">グーグルが開発を進めている、写真を「自動的に説明する」技術</a>”.   wired (2014年11月20日). <span title="">2015年5月18日</span>閲覧。</cite></span>
</li>
<li id="cite_note-pcw632-27"><b><a href="#cite_ref-pcw632_27-0">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://pc.watch.impress.co.jp/docs/column/kaigai/20140417_644632.html" rel="nofollow">ディープラーニングというGPUの新市場</a>”.   PC Watch (2014年4月17日). <span title="">2015年5月21日</span>閲覧。</cite></span>
</li>
<li id="cite_note-28"><b><a href="#cite_ref-28">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://gigazine.net/news/20141213-images-to-text/" rel="nofollow">画像をアップすると自動で説明文を生成してくれる「Images to Text」</a>”.   GIGAZINE (2014年12月13日). <span title="">2015年5月21日</span>閲覧。</cite></span>
</li>
<li id="cite_note-29"><b><a href="#cite_ref-29">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://wired.jp/2014/11/20/google-image-recognition/" rel="nofollow">グーグルが開発を進めている、写真を「自動的に説明する」技術</a>”.   WIRED (2014年11月20日). <span title="">2015年5月30日</span>閲覧。</cite></span>
</li>
<li id="cite_note-30"><b><a href="#cite_ref-30">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://wired.jp/2014/09/09/google-research-object-recognition/" rel="nofollow">人工知能は世界をもっと認識できる：グーグルのコンピューターヴィジョン</a>”.   WIRED (2014年9月9日). <span title="">2015年5月30日</span>閲覧。</cite></span>
</li>
<li id="cite_note-31"><b><a href="#cite_ref-31">^</a></b> <span class="reference-text"><a class="external text" href="http://www.4gamer.net/games/999/G999902/20150829007/" rel="nofollow">CEDEC 2015 画像認識ではすでに人間を凌駕。ディープラーニングが日本を再生する</a>松尾豊東京大学大学院准教授の発表スライドから</span>
</li>
<li id="cite_note-32"><b><a href="#cite_ref-32">^</a></b> <span class="reference-text">
<cite class="citation web" style="font-style:normal">ITTOUSAI (2016年1月28日). “<a class="external text" href="http://japanese.engadget.com/2016/01/28/google-ai-alphago/" rel="nofollow">Googleの囲碁AI『AlphaGo』がプロ棋士に勝利、史上初の快挙。自己対局を機械学習して上達</a>”.   Engadget. <span title="">2016年3月2日</span>閲覧。</cite></span>
</li>
<li id="cite_note-33"><b><a href="#cite_ref-33">^</a></b> <span class="reference-text">
<cite class="citation web" style="font-style:normal">CADE METZ (2016年1月31日). “<a class="external text" href="http://wired.jp/2016/01/31/huge-breakthrough-google-ai/" rel="nofollow">「囲碁の謎」を解いたグーグルの超知能は、人工知能の進化を10年早めた</a>”.   WIRED. <span title="">2016年3月2日</span>閲覧。</cite></span>
</li>
<li id="cite_note-34"><b><a href="#cite_ref-34">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="http://japanese.joins.com/article/276/213276.html" rel="nofollow">“＜囲碁：人間ｖｓ人工知能＞李世ドル「必ず勝ちたかったが、３連敗した時より今日のほうが辛かった」”</a>. <a href="/wiki/%E4%B8%AD%E5%A4%AE%E6%97%A5%E5%A0%B1" title="中央日報">中央日報</a>. (2016年3月16日)<span style="display:none;">. <a class="external free" href="http://japanese.joins.com/article/276/213276.html" rel="nofollow">http://japanese.joins.com/article/276/213276.html</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%EF%BC%9C%E5%9B%B2%E7%A2%81%EF%BC%9A%E4%BA%BA%E9%96%93%EF%BD%96%EF%BD%93%E4%BA%BA%E5%B7%A5%E7%9F%A5%E8%83%BD%EF%BC%9E%E6%9D%8E%E4%B8%96%E3%83%89%E3%83%AB%E3%80%8C%E5%BF%85%E3%81%9A%E5%8B%9D%E3%81%A1%E3%81%9F%E3%81%8B%E3%81%A3%E3%81%9F%E3%81%8C%E3%80%81%EF%BC%93%E9%80%A3%E6%95%97%E3%81%97%E3%81%9F%E6%99%82%E3%82%88%E3%82%8A%E4%BB%8A%E6%97%A5%E3%81%AE%E3%81%BB%E3%81%86%E3%81%8C%E8%BE%9B%E3%81%8B%E3%81%A3%E3%81%9F%E3%80%8D&amp;rft.atitle=&amp;rft.date=2016%E5%B9%B43%E6%9C%8816%E6%97%A5&amp;rft.pub=%5B%5B%E4%B8%AD%E5%A4%AE%E6%97%A5%E5%A0%B1%5D%5D&amp;rft_id=http%3A%2F%2Fjapanese.joins.com%2Farticle%2F276%2F213276.html&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-35"><b><a href="#cite_ref-35">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://www.nihonkiin.or.jp/match_news/match_result/alphago33.html" rel="nofollow">AlphaGoが最終戦も勝利で3連勝</a>”.   <a href="/wiki/%E6%97%A5%E6%9C%AC%E6%A3%8B%E9%99%A2" title="日本棋院">日本棋院</a> (2017年5月27日). <span title="">2018年2月7日</span>閲覧。</cite></span>
</li>
<li id="cite_note-36"><b><a href="#cite_ref-36">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://www.itmedia.co.jp/news/articles/1312/10/news076.html" rel="nofollow">Facebook、人工知能研究ラボを立ち上げ</a>”.   ITMedia News (2013年12月10日). <span title="">2015年5月22日</span>閲覧。</cite></span>
</li>
<li id="cite_note-37"><b><a href="#cite_ref-37">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="https://www.itmedia.co.jp/enterprise/articles/1501/19/news069.html" rel="nofollow">Facebook、ディープラーニング開発環境「Torch」向けモジュールをオープンソースで公開</a>”.   ITMedia News (2015年1月19日). <span title="">2015年5月22日</span>閲覧。</cite></span>
</li>
<li id="cite_note-38"><b><a href="#cite_ref-38">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://japan.zdnet.com/article/35059155/" rel="nofollow">Facebook、ディープラーニング技術をオープンソースに</a>”.   ZDNet Japan (2015年1月19日). <span title="">2015年5月22日</span>閲覧。</cite></span>
</li>
<li id="cite_note-nmt001-39"><b><a href="#cite_ref-nmt001_39-0">^</a></b> <span class="reference-text">中澤敏明、<a class="external text" href="https://doi.org/10.1241/johokanri.60.299" rel="nofollow">機械翻訳の新しいパラダイム：ニューラル機械翻訳の原理</a> 『情報管理』 2017年 60巻 5号 p.299-306, <a href="/wiki/%E3%83%87%E3%82%B8%E3%82%BF%E3%83%AB%E3%82%AA%E3%83%96%E3%82%B8%E3%82%A7%E3%82%AF%E3%83%88%E8%AD%98%E5%88%A5%E5%AD%90" title="デジタルオブジェクト識別子">doi</a>:<a class="external text" href="https://doi.org/10.1241%2Fjohokanri.60.299" rel="nofollow">10.1241/johokanri.60.299</a></span>
</li>
<li id="cite_note-40"><b><a href="#cite_ref-40">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="http://news.mynavi.jp/articles/2015/05/20/automotive201501/" rel="nofollow">人とくるまのテクノロジー展2015 - 「ディープラーニング」を採用したZMPのRoboCar MiniVan</a>”.   マイナビニュース (2015年5月20日). <span title="">2015年5月26日</span>閲覧。</cite></span>
</li>
<li id="cite_note-41"><b><a href="#cite_ref-41">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="http://jp.wsj.com/articles/SB11588421679375374726504583234572468806316" rel="nofollow">“顔認証で市民監視、中国の新たなAIツール”</a>. <a href="/wiki/%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB%E3%83%BB%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%88%E3%83%BB%E3%82%B8%E3%83%A3%E3%83%BC%E3%83%8A%E3%83%AB" title="ウォール・ストリート・ジャーナル">ウォール・ストリート・ジャーナル</a>. (2017年6月30日)<span style="display:none;">. <a class="external free" href="http://jp.wsj.com/articles/SB11588421679375374726504583234572468806316" rel="nofollow">http://jp.wsj.com/articles/SB11588421679375374726504583234572468806316</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E9%A1%94%E8%AA%8D%E8%A8%BC%E3%81%A7%E5%B8%82%E6%B0%91%E7%9B%A3%E8%A6%96%E3%80%81%E4%B8%AD%E5%9B%BD%E3%81%AE%E6%96%B0%E3%81%9F%E3%81%AAAI%E3%83%84%E3%83%BC%E3%83%AB&amp;rft.atitle=&amp;rft.date=2017%E5%B9%B46%E6%9C%8830%E6%97%A5&amp;rft.pub=%5B%5B%E3%82%A6%E3%82%A9%E3%83%BC%E3%83%AB%E3%83%BB%E3%82%B9%E3%83%88%E3%83%AA%E3%83%BC%E3%83%88%E3%83%BB%E3%82%B8%E3%83%A3%E3%83%BC%E3%83%8A%E3%83%AB%5D%5D&amp;rft_id=http%3A%2F%2Fjp.wsj.com%2Farticles%2FSB11588421679375374726504583234572468806316&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-42"><b><a href="#cite_ref-42">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="https://jp.reuters.com/article/china-facial-recognition-firms-idJPKBN1DF0PT" rel="nofollow">“アングル：中国の顔認証技術に活況投資、監視用の需要も後押し”</a>. <a href="/wiki/%E3%83%AD%E3%82%A4%E3%82%BF%E3%83%BC" title="ロイター">ロイター</a>. (2017年11月18日)<span style="display:none;">. <a class="external free" href="https://jp.reuters.com/article/china-facial-recognition-firms-idJPKBN1DF0PT" rel="nofollow">https://jp.reuters.com/article/china-facial-recognition-firms-idJPKBN1DF0PT</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E3%82%A2%E3%83%B3%E3%82%B0%E3%83%AB%EF%BC%9A%E4%B8%AD%E5%9B%BD%E3%81%AE%E9%A1%94%E8%AA%8D%E8%A8%BC%E6%8A%80%E8%A1%93%E3%81%AB%E6%B4%BB%E6%B3%81%E6%8A%95%E8%B3%87%E3%80%81%E7%9B%A3%E8%A6%96%E7%94%A8%E3%81%AE%E9%9C%80%E8%A6%81%E3%82%82%E5%BE%8C%E6%8A%BC%E3%81%97&amp;rft.atitle=&amp;rft.date=2017%E5%B9%B411%E6%9C%8818%E6%97%A5&amp;rft.pub=%5B%5B%E3%83%AD%E3%82%A4%E3%82%BF%E3%83%BC%5D%5D&amp;rft_id=https%3A%2F%2Fjp.reuters.com%2Farticle%2Fchina-facial-recognition-firms-idJPKBN1DF0PT&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-43"><b><a href="#cite_ref-43">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="http://wpb.shueisha.co.jp/2018/02/03/99109/" rel="nofollow">“中国の「超ＡＩ監視社会」－－新疆ウイグル自治区では“体内”まで監視！”</a>. <a href="/wiki/%E9%9B%86%E8%8B%B1%E7%A4%BE" title="集英社">集英社</a>. (2018年2月3日)<span style="display:none;">. <a class="external free" href="http://wpb.shueisha.co.jp/2018/02/03/99109/" rel="nofollow">http://wpb.shueisha.co.jp/2018/02/03/99109/</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E4%B8%AD%E5%9B%BD%E3%81%AE%E3%80%8C%E8%B6%85%EF%BC%A1%EF%BC%A9%E7%9B%A3%E8%A6%96%E7%A4%BE%E4%BC%9A%E3%80%8D%EF%BC%8D%EF%BC%8D%E6%96%B0%E7%96%86%E3%82%A6%E3%82%A4%E3%82%B0%E3%83%AB%E8%87%AA%E6%B2%BB%E5%8C%BA%E3%81%A7%E3%81%AF%E2%80%9C%E4%BD%93%E5%86%85%E2%80%9D%E3%81%BE%E3%81%A7%E7%9B%A3%E8%A6%96%EF%BC%81&amp;rft.atitle=&amp;rft.date=2018%E5%B9%B42%E6%9C%883%E6%97%A5&amp;rft.pub=%5B%5B%E9%9B%86%E8%8B%B1%E7%A4%BE%5D%5D&amp;rft_id=http%3A%2F%2Fwpb.shueisha.co.jp%2F2018%2F02%2F03%2F99109%2F&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-44"><b><a href="#cite_ref-44">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="http://japanese.engadget.com/2018/01/19/300m/" rel="nofollow">“中国、新疆ウイグル自治区で顔認識システム運用をテスト。指定地域から300m以上離れると当局に警告”</a>. <a href="/wiki/Engadget" title="Engadget">Engadget</a>. (2018年1月20日)<span style="display:none;">. <a class="external free" href="http://japanese.engadget.com/2018/01/19/300m/" rel="nofollow">http://japanese.engadget.com/2018/01/19/300m/</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E4%B8%AD%E5%9B%BD%E3%80%81%E6%96%B0%E7%96%86%E3%82%A6%E3%82%A4%E3%82%B0%E3%83%AB%E8%87%AA%E6%B2%BB%E5%8C%BA%E3%81%A7%E9%A1%94%E8%AA%8D%E8%AD%98%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%E9%81%8B%E7%94%A8%E3%82%92%E3%83%86%E3%82%B9%E3%83%88%E3%80%82%E6%8C%87%E5%AE%9A%E5%9C%B0%E5%9F%9F%E3%81%8B%E3%82%89300m%E4%BB%A5%E4%B8%8A%E9%9B%A2%E3%82%8C%E3%82%8B%E3%81%A8%E5%BD%93%E5%B1%80%E3%81%AB%E8%AD%A6%E5%91%8A&amp;rft.atitle=&amp;rft.date=2018%E5%B9%B41%E6%9C%8820%E6%97%A5&amp;rft.pub=%5B%5BEngadget%5D%5D&amp;rft_id=http%3A%2F%2Fjapanese.engadget.com%2F2018%2F01%2F19%2F300m%2F&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-45"><b><a href="#cite_ref-45">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="https://wired.jp/2017/08/16/america-china-ai-ascension/" rel="nofollow">“中国が「AI超大国」になる動きは、もはや誰にも止められない”</a>. <a class="mw-redirect" href="/wiki/WIRED" title="WIRED">WIRED</a>. (2017年8月16日)<span style="display:none;">. <a class="external free" href="https://wired.jp/2017/08/16/america-china-ai-ascension/" rel="nofollow">https://wired.jp/2017/08/16/america-china-ai-ascension/</a></span> <span class="reference-accessdate"><span title="">2018年2月7日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E4%B8%AD%E5%9B%BD%E3%81%8C%E3%80%8CAI%E8%B6%85%E5%A4%A7%E5%9B%BD%E3%80%8D%E3%81%AB%E3%81%AA%E3%82%8B%E5%8B%95%E3%81%8D%E3%81%AF%E3%80%81%E3%82%82%E3%81%AF%E3%82%84%E8%AA%B0%E3%81%AB%E3%82%82%E6%AD%A2%E3%82%81%E3%82%89%E3%82%8C%E3%81%AA%E3%81%84&amp;rft.atitle=&amp;rft.date=2017%E5%B9%B48%E6%9C%8816%E6%97%A5&amp;rft.pub=%5B%5BWIRED%5D%5D&amp;rft_id=https%3A%2F%2Fwired.jp%2F2017%2F08%2F16%2Famerica-china-ai-ascension%2F&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-46"><b><a href="#cite_ref-46">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="https://www.sankeibiz.jp/macro/news/190401/mcb1904010710001-n1.htm" rel="nofollow">“「深層学習の父」、中国のＡＩ利用に警鐘”</a>. <a class="mw-redirect" href="/wiki/Sankei_Biz" title="Sankei Biz">Sankei Biz</a>. (2019年4月1日)<span style="display:none;">. <a class="external free" href="https://www.sankeibiz.jp/macro/news/190401/mcb1904010710001-n1.htm" rel="nofollow">https://www.sankeibiz.jp/macro/news/190401/mcb1904010710001-n1.htm</a></span> <span class="reference-accessdate"><span title="">2019年4月5日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=%E3%80%8C%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92%E3%81%AE%E7%88%B6%E3%80%8D%E3%80%81%E4%B8%AD%E5%9B%BD%E3%81%AE%EF%BC%A1%EF%BC%A9%E5%88%A9%E7%94%A8%E3%81%AB%E8%AD%A6%E9%90%98&amp;rft.atitle=&amp;rft.date=2019%E5%B9%B44%E6%9C%881%E6%97%A5&amp;rft.pub=%5B%5BSankei+Biz%5D%5D&amp;rft_id=https%3A%2F%2Fwww.sankeibiz.jp%2Fmacro%2Fnews%2F190401%2Fmcb1904010710001-n1.htm&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-47"><b><a href="#cite_ref-47">^</a></b> <span class="reference-text"><cite class="citation news" style="font-style:normal"><a class="external text" href="https://www.bloomberg.com/news/articles/2019-02-02/deep-learning-godfather-bengio-worries-about-china-s-use-of-ai" rel="nofollow">“Deep Learning ‘Godfather’ Bengio Worries About China's Use of AI”</a>. <a href="/wiki/%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A0%E3%83%90%E3%83%BC%E3%82%B0_(%E4%BC%81%E6%A5%AD)" title="ブルームバーグ (企業)">ブルームバーグ</a>. (2019年2月2日)<span style="display:none;">. <a class="external free" href="https://www.bloomberg.com/news/articles/2019-02-02/deep-learning-godfather-bengio-worries-about-china-s-use-of-ai" rel="nofollow">https://www.bloomberg.com/news/articles/2019-02-02/deep-learning-godfather-bengio-worries-about-china-s-use-of-ai</a></span> <span class="reference-accessdate"><span title="">2019年4月5日</span>閲覧。</span></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.btitle=Deep+Learning+%E2%80%98Godfather%E2%80%99+Bengio+Worries+About+China%27s+Use+of+AI&amp;rft.atitle=&amp;rft.date=2019%E5%B9%B42%E6%9C%882%E6%97%A5&amp;rft.pub=%5B%5B%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A0%E3%83%90%E3%83%BC%E3%82%B0+%28%E4%BC%81%E6%A5%AD%29%7C%E3%83%96%E3%83%AB%E3%83%BC%E3%83%A0%E3%83%90%E3%83%BC%E3%82%B0%5D%5D&amp;rft_id=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Farticles%2F2019-02-02%2Fdeep-learning-godfather-bengio-worries-about-china-s-use-of-ai&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-48"><b><a href="#cite_ref-48">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="https://www.chunichi.co.jp/article/156918" rel="nofollow">AI使った偽ポルノ「被害に対する原状回復は絶望的なほど困難」“ディープフェイク”技術の問題点とは：中日スポーツ・東京中日スポーツ</a>” (日本語). <i>中日スポーツ・東京中日スポーツ</i>. <span title="">2021年3月31日</span>閲覧。</cite></span>
</li>
<li id="cite_note-49"><b><a href="#cite_ref-49">^</a></b> <span class="reference-text"><cite class="citation web" style="font-style:normal">“<a class="external text" href="https://securitynews.so-net.ne.jp/topics/sec_20009.html" rel="nofollow">AIだって騙される？AIの抱える弱点とは一体何か｜セキュリティ通信</a>” (日本語). <i>セキュリティ通信</i>. <span title="">2021年4月1日</span>閲覧。</cite></span>
</li>
<li id="cite_note-50"><b><a href="#cite_ref-50">^</a></b> <span class="reference-text"><cite class="citation journal" style="font-style:normal">Homma, Toshiteru; Les Atlas; Robert Marks II (1988). <a class="external text" href="http://papers.nips.cc/paper/20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf" rel="nofollow">“An Artificial Neural Network for Spatio-Temporal Bipolar Patters: Application to Phoneme Classification”</a>. <i>Advances in Neural Information Processing Systems 1</i>:  31–40<span style="display:none;">. <a class="external free" href="http://papers.nips.cc/paper/20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf" rel="nofollow">http://papers.nips.cc/paper/20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=An+Artificial+Neural+Network+for+Spatio-Temporal+Bipolar+Patters%3A+Application+to+Phoneme+Classification&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems+1&amp;rft.aulast=Homma&amp;rft.aufirst=Toshiteru&amp;rft.au=Homma%2C%26%2332%3BToshiteru&amp;rft.au=Les+Atlas&amp;rft.au=Robert+Marks+II&amp;rft.date=1988&amp;rft.pages=31%E2%80%9340&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-51"><b><a href="#cite_ref-51">^</a></b> <span class="reference-text"><cite class="citation journal" style="font-style:normal">Yann Le Cun (June 1989). <a class="external text" href="http://yann.lecun.com/exdb/publis/pdf/lecun-89.pdf" rel="nofollow"><i>Generalization and Network Design Strategies</i></a><span style="display:none;">. <a class="external free" href="http://yann.lecun.com/exdb/publis/pdf/lecun-89.pdf" rel="nofollow">http://yann.lecun.com/exdb/publis/pdf/lecun-89.pdf</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Generalization+and+Network+Design+Strategies&amp;rft.aulast=Yann+Le+Cun&amp;rft.au=Yann+Le+Cun&amp;rft.date=June+1989&amp;rft_id=http%3A%2F%2Fyann.lecun.com%2Fexdb%2Fpublis%2Fpdf%2Flecun-89.pdf&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-52"><b><a href="#cite_ref-52">^</a></b> <span class="reference-text"><cite class="citation journal" style="font-style:normal">Y. LeCun; B. Boser; J. S. Denker; D. Henderson; R. E. Howard; W. Hubbard; L. D. Jackel (1989). “Backpropagation applied to handwritten zip code recognition”. <i>Neural Computation</i> <b>1</b> (4):  541-551.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Backpropagation+applied+to+handwritten+zip+code+recognition&amp;rft.jtitle=Neural+Computation&amp;rft.aulast=Y.+LeCun&amp;rft.au=Y.+LeCun&amp;rft.au=B.+Boser&amp;rft.au=J.+S.+Denker&amp;rft.au=D.+Henderson&amp;rft.au=R.+E.+Howard&amp;rft.au=W.+Hubbard&amp;rft.au=L.+D.+Jackel&amp;rft.date=1989&amp;rft.volume=1&amp;rft.issue=4&amp;rft.pages=541-551&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-53"><b><a href="#cite_ref-53">^</a></b> <span class="reference-text"><cite class="citation journal" style="font-style:normal">Alex Krizhevsky; Ilya Sutskever; Geoffrey E. Hinton (2012). <a class="external text" href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-" rel="nofollow">“ImageNet Classification with Deep Convolutional Neural Networks”</a>. <i>Advances in Neural Information Processing Systems 25</i>:  1097-1105<span style="display:none;">. <a class="external free" href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-" rel="nofollow">http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-</a></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ImageNet+Classification+with+Deep+Convolutional+Neural+Networks&amp;rft.jtitle=Advances+in+Neural+Information+Processing+Systems+25&amp;rft.aulast=Alex+Krizhevsky&amp;rft.au=Alex+Krizhevsky&amp;rft.au=Ilya+Sutskever&amp;rft.au=Geoffrey+E.+Hinton&amp;rft.date=2012&amp;rft.pages=1097-1105&amp;rft_id=http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F4824-imagenet-classification-with-deep-&amp;rfr_id=info:sid/ja.wikipedia.org:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0"><span style="display: none;"> </span></span></span>
</li>
<li id="cite_note-54"><b><a href="#cite_ref-54">^</a></b> <span class="reference-text">岡谷貴之 深層学習 p11</span>
</li>
<li id="cite_note-55"><b><a href="#cite_ref-55">^</a></b> <span class="reference-text"><a class="external text" href="https://arxiv.org/abs/1806.02375" rel="nofollow">[1806.02375]バッチ正規化について</a></span>
</li>
<li id="cite_note-56"><b><a href="#cite_ref-56">^</a></b> <span class="reference-text"><a class="external text" href="https://github.com/arXivTimes/arXivTimes/issues/942" rel="nofollow">Understanding Batch Normalization · Issue #942 · arXivTimes/arXivTimes · GitHub</a></span>
</li>
<li id="cite_note-57"><b><a href="#cite_ref-57">^</a></b> <span class="reference-text"><a class="external text" href="https://jinbeizame.hateblo.jp/entry/understanding_batchnorm" rel="nofollow">論文紹介 Understanding Batch Normalization - じんべえざめのノート</a></span>
</li>
</ol></div></div>
<h2><span id=".E5.8F.82.E8.80.83.E6.96.87.E7.8C.AE"></span><span class="mw-headline" id="参考文献">参考文献</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=38" title="節を編集: 参考文献">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><cite class="citation book" id="CITEREF小林雅一2015" style="font-style:normal"><a class="new" href="/w/index.php?title=%E5%B0%8F%E6%9E%97%E9%9B%85%E4%B8%80&amp;action=edit&amp;redlink=1" title="小林雅一 (存在しないページ)">小林雅一</a>『AIの衝撃 人工知能は人類の敵か』講談社〈講談社現代新書〉、2015年3月20日、第1刷。<link href="mw-data:TemplateStyles:r2293413" rel="mw-deduplicated-inline-style"/><a href="/wiki/ISBN" title="ISBN">ISBN</a> <a href="/wiki/%E7%89%B9%E5%88%A5:%E6%96%87%E7%8C%AE%E8%B3%87%E6%96%99/978-4-06-288307-8" title="特別:文献資料/978-4-06-288307-8">978-4-06-288307-8</a>。</cite></li>
<li><cite class="citation book" id="CITEREF小林雅一2013" style="font-style:normal"><a class="new" href="/w/index.php?title=%E5%B0%8F%E6%9E%97%E9%9B%85%E4%B8%80&amp;action=edit&amp;redlink=1" title="小林雅一 (存在しないページ)">小林雅一</a>『クラウドからAIへ アップル、グーグル、フェイスブックの次なる主戦場』朝日新聞出版〈朝日新書〉、2013年7月30日、第1刷。<link href="mw-data:TemplateStyles:r2293413" rel="mw-deduplicated-inline-style"/><a href="/wiki/ISBN" title="ISBN">ISBN</a> <a href="/wiki/%E7%89%B9%E5%88%A5:%E6%96%87%E7%8C%AE%E8%B3%87%E6%96%99/978-4-02-273515-7" title="特別:文献資料/978-4-02-273515-7">978-4-02-273515-7</a>。</cite></li>
<li><cite class="citation book" id="CITEREF松尾豊2015" style="font-style:normal"><a href="/wiki/%E6%9D%BE%E5%B0%BE%E8%B1%8A" title="松尾豊">松尾豊</a>『人工知能は人間を超えるか ディープラーニングの先にあるもの』KADOKAWA〈角川EPUB選書〉、2015年3月11日、第1刷。<link href="mw-data:TemplateStyles:r2293413" rel="mw-deduplicated-inline-style"/><a href="/wiki/ISBN" title="ISBN">ISBN</a> <a href="/wiki/%E7%89%B9%E5%88%A5:%E6%96%87%E7%8C%AE%E8%B3%87%E6%96%99/978-4040800202" title="特別:文献資料/978-4040800202">978-4040800202</a>。</cite></li></ul>
<ul><li>園田翔：「深層ニューラルネットの積分表現理論」、早稲田大学博士論文（2017）。</li>
<li><a class="external text" href="http://www.airc.aist.go.jp/seminar_detail/docs/seminar02-sonoda.pdf" rel="nofollow">園田翔：「ニューラルネットの積分表現理論」</a></li></ul>
<h2><span id=".E9.96.A2.E9.80.A3.E9.A0.85.E7.9B.AE"></span><span class="mw-headline" id="関連項目">関連項目</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;section=39" title="節を編集: 関連項目">編集</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="div-col columns column-count column-count-3" style="-moz-column-count:3; -webkit-column-count:3; column-count:3; -moz-column-width: 18em; -webkit-column-width: 18em; column-width: 18em;">
<ul><li><a href="/wiki/%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="ニューラルネットワーク">ニューラルネットワーク</a></li>
<li><a href="/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92" title="機械学習">機械学習</a></li>
<li><a href="/wiki/%E9%9F%B3%E5%A3%B0%E8%AA%8D%E8%AD%98" title="音声認識">音声認識</a></li>
<li><a href="/wiki/%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E3%83%93%E3%82%B8%E3%83%A7%E3%83%B3" title="コンピュータビジョン">画像認識</a></li>
<li><a class="mw-redirect" href="/wiki/%E9%A1%94%E8%AA%8D%E8%AD%98" title="顔認識">顔認識</a></li>
<li><a href="/wiki/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86" title="自然言語処理">自然言語処理</a></li>
<li><a href="/wiki/%E5%89%B5%E8%96%AC" title="創薬">毒性学</a></li>
<li><a href="/wiki/%E9%A1%A7%E5%AE%A2%E9%96%A2%E4%BF%82%E7%AE%A1%E7%90%86" title="顧客関係管理">顧客関係管理</a></li>
<li><a href="/wiki/%E3%83%AC%E3%82%B3%E3%83%A1%E3%83%B3%E3%83%80%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0" title="レコメンダシステム">レコメンダシステム</a></li>
<li><a class="mw-redirect" href="/wiki/%E3%83%90%E3%82%A4%E3%82%AA%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%9E%E3%83%86%E3%82%A3%E3%83%83%E3%82%AF%E3%82%B9" title="バイオインフォマティックス">バイオインフォマティックス</a></li>
<li><a class="new" href="/w/index.php?title=%E5%8C%BB%E7%99%82%E7%94%BB%E5%83%8F%E5%88%86%E6%9E%90&amp;action=edit&amp;redlink=1" title="医療画像分析 (存在しないページ)">医療画像分析</a> (<a class="new" href="/w/index.php?title=En:Medical_image_analysis&amp;action=edit&amp;redlink=1" title="En:Medical image analysis (存在しないページ)">en:Medical image analysis</a>)</li>
<li><a class="new" href="/w/index.php?title=%E3%83%A2%E3%83%90%E3%82%A4%E3%83%AB%E5%BA%83%E5%91%8A&amp;action=edit&amp;redlink=1" title="モバイル広告 (存在しないページ)">モバイル広告</a> (<a class="new" href="/w/index.php?title=En:Mobile_advertising&amp;action=edit&amp;redlink=1" title="En:Mobile advertising (存在しないページ)">en:Mobile advertising</a>)</li>
<li><a class="new" href="/w/index.php?title=%E7%94%BB%E5%83%8F%E5%BE%A9%E5%85%83&amp;action=edit&amp;redlink=1" title="画像復元 (存在しないページ)">画像復元</a> (<a class="new" href="/w/index.php?title=En:Image_restoration&amp;action=edit&amp;redlink=1" title="En:Image restoration (存在しないページ)">en:Image restoration</a>)</li></ul>
</div>
<!-- 
NewPP limit report
Cached time: 20220401190134
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.743 seconds
Real time usage: 1.246 seconds
Preprocessor visited node count: 27274/1000000
Post‐expand include size: 240531/2097152 bytes
Template argument size: 57069/2097152 bytes
Highest expansion depth: 31/40
Expensive parser function count: 34/100
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 51758/5000000 bytes
Lua time usage: 0.360/7 seconds
Lua virtual size: 8851456/52428800 bytes
Lua estimated memory usage: 0 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1152.366      1 -total
 45.18%  520.618      2 テンプレート:Reflist
 23.48%  270.578      1 テンプレート:Machine_learning_bar
 23.12%  266.386      1 テンプレート:Sidebar_with_collapsible_lists
 19.54%  225.210     25 テンプレート:Cite_web
 17.10%  197.069     33 テンプレート:仮リンク
 14.91%  171.847      4 テンプレート:Cite_book
 14.13%  162.798      4 テンプレート:Cite_book/和書
 11.68%  134.579      4 テンプレート:ISBN2
  9.15%  105.475      4 テンプレート:Catalog_lookup_link
-->
<!-- Saved in parser cache with key my_wiki:pcache:idhash:3219531-0!canonical and timestamp 20220401190132 and revision id 1880795. Serialized with JSON.
 -->
</div>
<div class="printfooter">「<a dir="ltr" href="http://localhost:8080/w/index.php?title=ディープラーニング&amp;oldid=1880795">http://localhost:8080/w/index.php?title=ディープラーニング&amp;oldid=1880795</a>」から取得</div></div>
<div class="catlinks" data-mw="interface" id="catlinks"><div class="mw-normal-catlinks" id="mw-normal-catlinks"><a href="/wiki/%E7%89%B9%E5%88%A5:%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA" title="特別:カテゴリ">カテゴリ</a>: <ul><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E5%A3%8A%E3%82%8C%E3%81%9F%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E3%81%B8%E3%81%AE%E3%83%AA%E3%83%B3%E3%82%AF%E3%81%8C%E3%81%82%E3%82%8B%E3%83%9A%E3%83%BC%E3%82%B8" title="カテゴリ:壊れたファイルへのリンクがあるページ">壊れたファイルへのリンクがあるページ</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E6%9B%B8%E3%81%8D%E3%81%8B%E3%81%91%E3%81%AE%E7%AF%80%E3%81%AE%E3%81%82%E3%82%8B%E9%A0%85%E7%9B%AE" title="カテゴリ:書きかけの節のある項目">書きかけの節のある項目</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E5%87%BA%E5%85%B8%E3%82%92%E5%BF%85%E8%A6%81%E3%81%A8%E3%81%99%E3%82%8B%E7%AF%80%E3%81%AE%E3%81%82%E3%82%8B%E8%A8%98%E4%BA%8B/2015%E5%B9%B411%E6%9C%88-12%E6%9C%88" title="カテゴリ:出典を必要とする節のある記事/2015年11月-12月">出典を必要とする節のある記事/2015年11月-12月</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E9%9B%91%E5%A4%9A%E3%81%AA%E5%86%85%E5%AE%B9%E3%82%92%E7%AE%87%E6%9D%A1%E6%9B%B8%E3%81%8D%E3%81%97%E3%81%9F%E7%AF%80%E3%81%AE%E3%81%82%E3%82%8B%E8%A8%98%E4%BA%8B_-_2019%E5%B9%B41%E6%9C%88" title="カテゴリ:雑多な内容を箇条書きした節のある記事 - 2019年1月">雑多な内容を箇条書きした節のある記事 - 2019年1月</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:Div_col%E3%81%A73%E5%88%97%E3%82%92%E6%8C%87%E5%AE%9A%E3%81%97%E3%81%A6%E3%81%84%E3%82%8B%E3%83%9A%E3%83%BC%E3%82%B8" title="カテゴリ:Div colで3列を指定しているページ">Div colで3列を指定しているページ</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E4%BA%BA%E5%B7%A5%E3%83%8B%E3%83%A5%E3%83%BC%E3%83%A9%E3%83%AB%E3%83%8D%E3%83%83%E3%83%88%E3%83%AF%E3%83%BC%E3%82%AF" title="カテゴリ:人工ニューラルネットワーク">人工ニューラルネットワーク</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92" title="カテゴリ:機械学習">機械学習</a></li><li><a href="/wiki/%E3%82%AB%E3%83%86%E3%82%B4%E3%83%AA:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0" title="カテゴリ:ディープラーニング">ディープラーニング</a></li></ul></div></div>
</div>
</div>
<div id="mw-navigation">
<h2>案内メニュー</h2>
<div id="mw-head">
<nav aria-labelledby="p-personal-label" class="mw-portlet mw-portlet-personal vector-user-menu-legacy vector-menu" id="p-personal" role="navigation">
<h3 class="vector-menu-heading" id="p-personal-label"> <span>個人用ツール</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="mw-list-item" id="pt-anonuserpage">ログインしていません</li><li class="mw-list-item" id="pt-anontalk"><a accesskey="n" href="/wiki/%E7%89%B9%E5%88%A5:%E3%83%88%E3%83%BC%E3%82%AF%E3%83%9A%E3%83%BC%E3%82%B8" title="このIPアドレスからなされた編集についての議論 [n]">トーク</a></li><li class="mw-list-item" id="pt-anoncontribs"><a accesskey="y" href="/wiki/%E7%89%B9%E5%88%A5:%E8%87%AA%E5%88%86%E3%81%AE%E6%8A%95%E7%A8%BF%E8%A8%98%E9%8C%B2" title="このIPアドレスからなされた編集の一覧 [y]">投稿記録</a></li><li class="mw-list-item" id="pt-createaccount"><a href="/w/index.php?title=%E7%89%B9%E5%88%A5:%E3%82%A2%E3%82%AB%E3%82%A6%E3%83%B3%E3%83%88%E4%BD%9C%E6%88%90&amp;returnto=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;returntoquery=curid%3D3219531%26redirect%3Dno" title="アカウントを作成してログインすることをお勧めしますが、必須ではありません">アカウント作成</a></li><li class="mw-list-item" id="pt-login"><a accesskey="o" href="/w/index.php?title=%E7%89%B9%E5%88%A5:%E3%83%AD%E3%82%B0%E3%82%A4%E3%83%B3&amp;returnto=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;returntoquery=curid%3D3219531%26redirect%3Dno" title="ログインすることを推奨します。ただし、必須ではありません。 [o]">ログイン</a></li></ul>
</div>
</nav>
<div id="left-navigation">
<nav aria-labelledby="p-namespaces-label" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" id="p-namespaces" role="navigation">
<h3 class="vector-menu-heading" id="p-namespaces-label"> <span>名前空間</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="selected mw-list-item" id="ca-nstab-main"><a accesskey="c" href="/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0" title="本文を閲覧 [c]">ページ</a></li><li class="new mw-list-item" id="ca-talk"><a accesskey="t" href="/w/index.php?title=%E3%83%88%E3%83%BC%E3%82%AF:%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit&amp;redlink=1" rel="discussion" title="本文ページについての議論 (存在しないページ) [t]">ノート</a></li></ul>
</div>
</nav>
<nav aria-labelledby="p-variants-label" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu-dropdown-noicon vector-menu vector-menu-dropdown" id="p-variants" role="navigation">
<input aria-haspopup="true" aria-labelledby="p-variants-label" class="vector-menu-checkbox" data-event-name="ui.dropdown-p-variants" id="p-variants-checkbox" role="button" type="checkbox"/>
<h3 class="vector-menu-heading" id="p-variants-label"> <span>変種</span>
<span class="vector-menu-checkbox-expanded">拡張</span>
<span class="vector-menu-checkbox-collapsed">折り畳む</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"></ul>
</div>
</nav>
</div>
<div id="right-navigation">
<nav aria-labelledby="p-views-label" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" id="p-views" role="navigation">
<h3 class="vector-menu-heading" id="p-views-label"> <span>表示</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="selected mw-list-item" id="ca-view"><a href="/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0">閲覧</a></li><li class="mw-list-item" id="ca-edit"><a accesskey="e" href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=edit" title="このページを編集 [e]">編集</a></li><li class="mw-list-item" id="ca-history"><a accesskey="h" href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=history" title="このページの過去の版 [h]">履歴表示</a></li></ul>
</div>
</nav>
<nav aria-labelledby="p-cactions-label" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu-dropdown-noicon vector-menu vector-menu-dropdown" id="p-cactions" role="navigation" title="その他の操作">
<input aria-haspopup="true" aria-labelledby="p-cactions-label" class="vector-menu-checkbox" data-event-name="ui.dropdown-p-cactions" id="p-cactions-checkbox" role="button" type="checkbox"/>
<h3 class="vector-menu-heading" id="p-cactions-label"> <span>その他</span>
<span class="vector-menu-checkbox-expanded">拡張</span>
<span class="vector-menu-checkbox-collapsed">折り畳む</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"></ul>
</div>
</nav>
<div class="vector-search-box" id="p-search" role="search">
<div>
<h3>
<label for="searchInput">検索</label>
</h3>
<form action="/w/index.php" id="searchform">
<div data-search-loc="header-navigation" id="simpleSearch">
<input accesskey="f" autocapitalize="sentences" id="searchInput" name="search" placeholder="Wikipedia内を検索" title="Wikipedia内を検索 [f]" type="search"/>
<input name="title" type="hidden" value="特別:検索"/>
<input class="searchButton mw-fallbackSearchButton" id="mw-searchButton" name="fulltext" title="この文字列が含まれるページを探す" type="submit" value="検索"/>
<input class="searchButton" id="searchButton" name="go" title="厳密に一致する名前のページが存在すれば、そのページへ移動する" type="submit" value="表示"/>
</div>
</form>
</div>
</div>
</div>
</div>
<div id="mw-panel">
<div id="p-logo" role="banner">
<a class="mw-wiki-logo" href="/wiki/%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%9A%E3%83%BC%E3%82%B8" title="メインページに移動する"></a>
</div>
<nav aria-labelledby="p-navigation-label" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal" id="p-navigation" role="navigation">
<h3 class="vector-menu-heading" id="p-navigation-label"> <span>案内</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="mw-list-item" id="n-mainpage-description"><a accesskey="z" href="/wiki/%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%9A%E3%83%BC%E3%82%B8" title="メインページに移動する [z]">メインページ</a></li><li class="mw-list-item" id="n-portal"><a href="/wiki/Wikipedia:%E3%82%B3%E3%83%9F%E3%83%A5%E3%83%8B%E3%83%86%E3%82%A3%E3%83%BB%E3%83%9D%E3%83%BC%E3%82%BF%E3%83%AB" title="このプロジェクトについて、できること、情報を入手する場所">コミュニティ・ポータル</a></li><li class="mw-list-item" id="n-currentevents"><a href="/wiki/Portal:%E6%9C%80%E8%BF%91%E3%81%AE%E5%87%BA%E6%9D%A5%E4%BA%8B" title="最近の出来事の背景を知る">最近の出来事</a></li><li class="mw-list-item" id="n-newpages"><a href="/wiki/%E7%89%B9%E5%88%A5:%E6%96%B0%E3%81%97%E3%81%84%E3%83%9A%E3%83%BC%E3%82%B8" title="最近新規に作成されたページの一覧">新しいページ</a></li><li class="mw-list-item" id="n-recentchanges"><a accesskey="r" href="/wiki/%E7%89%B9%E5%88%A5:%E6%9C%80%E8%BF%91%E3%81%AE%E6%9B%B4%E6%96%B0" title="このウィキにおける最近の更新の一覧 [r]">最近の更新</a></li><li class="mw-list-item" id="n-randompage"><a accesskey="x" href="/wiki/%E7%89%B9%E5%88%A5:%E3%81%8A%E3%81%BE%E3%81%8B%E3%81%9B%E8%A1%A8%E7%A4%BA" title="無作為に選択されたページを読み込む [x]">おまかせ表示</a></li><li class="mw-list-item" id="n-sandbox"><a href="/wiki/Wikipedia:%E3%82%B5%E3%83%B3%E3%83%89%E3%83%9C%E3%83%83%E3%82%AF%E3%82%B9" title="練習用のページ">練習用ページ</a></li><li class="mw-list-item" id="n-commonsupload"><a href="//commons.wikimedia.org/wiki/Special:UploadWizard?uselang=ja" rel="nofollow" title="画像やメディアファイルをウィキメディア・コモンズにアップロード">アップロード (ウィキメディア・コモンズ)</a></li></ul>
</div>
</nav>
<nav aria-labelledby="p-help-label" class="mw-portlet mw-portlet-help vector-menu vector-menu-portal portal" id="p-help" role="navigation">
<h3 class="vector-menu-heading" id="p-help-label"> <span>ヘルプ</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="mw-list-item" id="n-help"><a href="/wiki/%E3%83%98%E3%83%AB%E3%83%97:%E7%9B%AE%E6%AC%A1" title="情報を得る場所">ヘルプ</a></li><li class="mw-list-item" id="n-villagepump"><a href="/wiki/Wikipedia:%E4%BA%95%E6%88%B8%E7%AB%AF" title="プロジェクトについての意見交換">井戸端</a></li><li class="mw-list-item" id="n-notice"><a href="/wiki/Wikipedia:%E3%81%8A%E7%9F%A5%E3%82%89%E3%81%9B" title="プロジェクトについてのお知らせ">お知らせ</a></li><li class="mw-list-item" id="n-bugreportspage"><a href="/wiki/Wikipedia:%E3%83%90%E3%82%B0%E3%81%AE%E5%A0%B1%E5%91%8A" title="ウィキペディア・ソフトウェアのバグ報告">バグの報告</a></li><li class="mw-list-item" id="n-sitesupport"><a href="//donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_ja.wikipedia.org&amp;uselang=ja" rel="nofollow">sitesupport</a></li><li class="mw-list-item" id="n-contact"><a href="/wiki/Wikipedia:%E9%80%A3%E7%B5%A1%E5%85%88" title="ウィキペディアやウィキメディア財団に関する連絡先">ウィキペディアに関するお問い合わせ</a></li></ul>
</div>
</nav>
<nav aria-labelledby="p-tb-label" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" id="p-tb" role="navigation">
<h3 class="vector-menu-heading" id="p-tb-label"> <span>ツール</span>
</h3>
<div class="vector-menu-content">
<ul class="vector-menu-content-list"><li class="mw-list-item" id="t-whatlinkshere"><a accesskey="j" href="/wiki/%E7%89%B9%E5%88%A5:%E3%83%AA%E3%83%B3%E3%82%AF%E5%85%83/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0" title="ここにリンクしている全ウィキページの一覧 [j]">リンク元</a></li><li class="mw-list-item" id="t-recentchangeslinked"><a accesskey="k" href="/wiki/%E7%89%B9%E5%88%A5:%E9%96%A2%E9%80%A3%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AE%E6%9B%B4%E6%96%B0%E7%8A%B6%E6%B3%81/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0" rel="nofollow" title="このページからリンクしているページの最近の更新 [k]">関連ページの更新状況</a></li><li class="mw-list-item" id="t-specialpages"><a accesskey="q" href="/wiki/%E7%89%B9%E5%88%A5:%E7%89%B9%E5%88%A5%E3%83%9A%E3%83%BC%E3%82%B8%E4%B8%80%E8%A6%A7" title="特別ページの一覧 [q]">特別ページ</a></li><li class="mw-list-item" id="t-print"><a accesskey="p" href="javascript:print();" rel="alternate" title="このページの印刷用ページ [p]">印刷用バージョン</a></li><li class="mw-list-item" id="t-permalink"><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;oldid=1880795" title="このページのこの版への固定リンク">この版への固定リンク</a></li><li class="mw-list-item" id="t-info"><a href="/w/index.php?title=%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0&amp;action=info" title="このページについての詳細情報">ページ情報</a></li></ul>
</div>
</nav>
</div>
</div>
<footer class="mw-footer" id="footer" role="contentinfo">
<ul id="footer-info">
<li id="footer-info-lastmod"> 最終更新 2021年6月8日 (火) 04:23 （日時は<a href="/wiki/%E7%89%B9%E5%88%A5:%E5%80%8B%E4%BA%BA%E8%A8%AD%E5%AE%9A#mw-prefsection-rendering" title="特別:個人設定">個人設定</a>で未設定ならば<a href="/wiki/%E5%8D%94%E5%AE%9A%E4%B8%96%E7%95%8C%E6%99%82" title="協定世界時">UTC</a>）。</li>
</ul>
<ul id="footer-places">
<li id="footer-places-privacy"><a href="/wiki/Wikipedia:%E3%83%97%E3%83%A9%E3%82%A4%E3%83%90%E3%82%B7%E3%83%BC%E3%83%BB%E3%83%9D%E3%83%AA%E3%82%B7%E3%83%BC" title="Wikipedia:プライバシー・ポリシー">プライバシー・ポリシー</a></li>
<li id="footer-places-about"><a href="/wiki/Wikipedia:%E3%82%A6%E3%82%A3%E3%82%AD%E3%83%9A%E3%83%87%E3%82%A3%E3%82%A2%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6" title="Wikipedia:ウィキペディアについて">ウィキペディアについて</a></li>
<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:%E5%85%8D%E8%B2%AC%E4%BA%8B%E9%A0%85" title="Wikipedia:免責事項">免責事項</a></li>
</ul>
<ul class="noprint" id="footer-icons">
<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img alt="Powered by MediaWiki" height="31" loading="lazy" src="/w/resources/assets/poweredby_mediawiki_88x31.png" srcset="/w/resources/assets/poweredby_mediawiki_132x47.png 1.5x, /w/resources/assets/poweredby_mediawiki_176x62.png 2x" width="88"/></a></li>
</ul>
</footer>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.743","walltime":"1.246","ppvisitednodes":{"value":27274,"limit":1000000},"postexpandincludesize":{"value":240531,"limit":2097152},"templateargumentsize":{"value":57069,"limit":2097152},"expansiondepth":{"value":31,"limit":40},"expensivefunctioncount":{"value":34,"limit":100},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":51758,"limit":5000000},"timingprofile":["100.00% 1152.366      1 -total"," 45.18%  520.618      2 テンプレート:Reflist"," 23.48%  270.578      1 テンプレート:Machine_learning_bar"," 23.12%  266.386      1 テンプレート:Sidebar_with_collapsible_lists"," 19.54%  225.210     25 テンプレート:Cite_web"," 17.10%  197.069     33 テンプレート:仮リンク"," 14.91%  171.847      4 テンプレート:Cite_book"," 14.13%  162.798      4 テンプレート:Cite_book/和書"," 11.68%  134.579      4 テンプレート:ISBN2","  9.15%  105.475      4 テンプレート:Catalog_lookup_link"]},"scribunto":{"limitreport-timeusage":{"value":"0.360","limit":"7"},"limitreport-virtmemusage":{"value":8851456,"limit":52428800},"limitreport-estmemusage":0},"cachereport":{"timestamp":"20220401190134","ttl":86400,"transientcontent":false}}});mw.config.set({"wgBackendResponseTime":1475});});</script>
</body></html>